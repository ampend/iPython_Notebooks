{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017-10-12\n",
    "# A. Pendleton\n",
    "# Patterns of the non-reference and reference cfERV insertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this uses iPython magic to make plots appear inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "def count_lines(f):\n",
    "    lineCount = 0\n",
    "    with open(f, 'r') as f:\n",
    "        for line in f:\n",
    "            lineCount += 1\n",
    "        return lineCount\n",
    "def runCMD(cmd):\n",
    "    val = subprocess.Popen(cmd, shell=True).wait()\n",
    "    if val == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print ('command failed')\n",
    "        print (cmd)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Root directory and the bedfiles for the non-reference and reference insertions\n",
    "ervDir = '/home/ampend/links/kidd-lab/ampend-projects/cfERVs/'\n",
    "bedfiles = [ervDir + 'input/cfERV_NonReferenceInsertionSites_2017-06-29.bed',ervDir + 'input/cfERV_ReferenceInsertionSites_2017-06-29.bed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Reading in coordinates from the following ERV insertion site bed file:\n",
      " /home/ampend/links/kidd-lab/ampend-projects/cfERVs/input/cfERV_NonReferenceInsertionSites_2017-06-29.bed\n",
      "#There are a total of 59 cfERV insertions in this bed file\n",
      "\n",
      "#Reading in coordinates from the following ERV insertion site bed file:\n",
      " /home/ampend/links/kidd-lab/ampend-projects/cfERVs/input/cfERV_ReferenceInsertionSites_2017-06-29.bed\n",
      "#There are a total of 107 cfERV insertions in this bed file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for File in bedfiles:\n",
    "    print('#Reading in coordinates from the following ERV insertion site bed file:\\n', File)\n",
    "    f = File\n",
    "    lineCount = count_lines(f)\n",
    "    print('#There are a total of %i cfERV insertions in this bed file\\n' % (lineCount))\n",
    "    bedFile = open(f, 'r')\n",
    "\n",
    "    ervDict = {}\n",
    "\n",
    "    for line in bedFile:\n",
    "        line = line.rstrip()\n",
    "        line = line.split('\\t')\n",
    "        chrom = line[0]\n",
    "        start = int(line[1])\n",
    "        end = int(line[2])\n",
    "        ID = line[3]\n",
    "        if 'NonReference' in File:\n",
    "            insertionType = 'NonReference'\n",
    "        else:\n",
    "            insertionType = 'Reference'\n",
    "        ervDict[ID] = [chrom,start,end,ID,'Genes','Olfactory','FST','VST',insertionType]\n",
    "    bedFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_intersects(a, b, outfile):\n",
    "    cmd = 'bedtools intersect -wo -a %s -b %s > %s' % (a, b, outfile)\n",
    "    #print(cmd)\n",
    "    runCMD(cmd)\n",
    "    Dict = process_intersect(outfile)\n",
    "    return Dict\n",
    "########################################################################################\n",
    "def process_intersect(outfile):\n",
    "    Dict={}\n",
    "    for line in open(outfile,'r'):\n",
    "        line=line.rstrip().split()\n",
    "        chrom,start,end,ID = line[0:4]\n",
    "        hitID = line[7]\n",
    "        if ID in Dict.keys():\n",
    "            Dict[ID].append(hitID)\n",
    "        else:\n",
    "            Dict[ID] = []\n",
    "            Dict[ID].append(hitID)\n",
    "    return Dict\n",
    "########################################################################################\n",
    "def do_window_intersects(a,b,windowSize,outfile):\n",
    "    cmd = 'bedtools window -w %i -a %s -b %s > %s' % (windowSize, a, b, outfile)\n",
    "    #print(cmd)\n",
    "    runCMD(cmd)\n",
    "##############################################################################################################\n",
    "def make_ensG_dict(ervfile):\n",
    "    ensGDict = {}\n",
    "    for line in open(ervfile,'r'):\n",
    "        line = line.rstrip().split()\n",
    "        winID = line[3]\n",
    "        ensGDict[winID] = [[],[],[],[],[],[]]  \n",
    "    return ensGDict\n",
    "##############################################################################################################\n",
    "def parse_gene_intersect_file(Dict,intfile,windowLength,index):\n",
    "    intersectFile = open(intfile,'r') #outfile from the intersect step with ensembl 81 genes\n",
    "\n",
    "    ensID = ''\n",
    "    sigGenes = [] #To keep track of all gene IDs (ENSCAFG) that are in sig windows\n",
    "\n",
    "    #Reading the intersect file results\n",
    "    for line in intersectFile:\n",
    "        line = line.rstrip() #removing extraneous whitespace characters\n",
    "        line = line.split('\\t') #delimiting \"columns\" in the file based on tabs\t\t\n",
    "        winID = line[3]\n",
    "        if '_' in line[7]:\n",
    "            hit = line[7].split('_')\n",
    "            Protein = hit[0]\n",
    "            Gene = hit[1]\n",
    "            b2goID = Gene + '|' + Protein\n",
    "            ensGID = hit[2]\n",
    "        else:\n",
    "            ensGID = line[7]\n",
    "        if Dict not in Dict[winID][index]:\n",
    "            Dict[winID][index].append(ensGID)\n",
    "    intersectFile.close()\n",
    "   \n",
    "    return Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_summary_text_files(ervDir,Type,ervfile,ensGDict,otherDict,estDict,vcdrDict,xpclrDict,axDict):\n",
    "    inFile = open(ervfile, 'r')\n",
    "\n",
    "    ############################################################################\n",
    "    # SUMMARIZING ERV INSERTIONS WITH ENSEMBL GENES AND FST REGIONS\n",
    "    ##########################################################################\n",
    "    Outfile = ervDir + 'results/' + Type + '_cfERV_WithFSTIntersects_GeneTable.txt' #Write out the VST Summary data table here\n",
    "    outFile = open(Outfile, 'w')\n",
    "    outFile.write('Chrom\\tStart\\tEnd\\tWindow ID\\tERV Type\\t0kb Intersecting Ensembl Genes\\t5kb Intersecting Ensembl Genes\\t10kb Intersecting EnsemblGenes\\t25kb Intersecting Ensembl Genes\\t50kb  Intersecting Ensembl Genes\\t100kb  Intersecting Ensembl Genes\\t0kb Intersecting Dog ESTs\\t5kb Intersecting Dog ESTs\\t10kb Intersecting Dog ESTs\\t25kb Intersecting Dog ESTs\\t50kb Intersecting Dog ESTs\\t100kb Intersecting Dog ESTs\\t0kb Intersecting \"Other\" RefSeq Genes\\t50kb Intersecting FST CDR\\t50kb Intersecting XP-CLR CDR\\t50kb Intersecting VST VCDR\\t50kb Intersecting Axelsson CDR\\n')\n",
    "\n",
    "    allDict = {} # defining the dictionary that will have all the results of bedtool intersect compiled by windows\n",
    "\n",
    "    for line in inFile:\n",
    "        line = line.rstrip()\n",
    "        line = line.split('\\t')\n",
    "        chrom, start_pos, end_pos, WinID = line[0:4]\n",
    "        allDict[WinID] = [chrom,start_pos,end_pos,WinID,Type,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False] #setting up empty dictionary\n",
    "        #Open up dictionary for ERVs\n",
    "        #0=chr, 1=start_pos, 2=end_pos, 3=ERV ID 4=ERV Type (reference/nonreference)\n",
    "        #5=Intersects with Ensembl Gene IDs (default = False) at 0kb\n",
    "        #6=Intersects with Ensembl Gene IDs (default = False) at 5kb\n",
    "        #7=Intersects with Ensembl Gene IDs (default = False) at 10kb\n",
    "        #8=Intersects with Ensembl Gene IDs (default = False) at 25kb\n",
    "        #9=Intersects with Ensembl Gene IDs (default = False) at 50kb\n",
    "        #10=Intersects with Ensembl Gene IDs (default = False) at 100kb\n",
    "        #11 = Intersects Dog EST (from UCSC) at 0kb\n",
    "        #12 = Intersects Dog EST (from UCSC) at 5kb\n",
    "        #13 = Intersects Dog EST (from UCSC) at 10kb\n",
    "        #14 = Intersects Dog EST (from UCSC) at 25kb\n",
    "        #15 = Intersects Dog EST (from UCSC) at 50kb\n",
    "        #16 = Intersects Dog EST (from UCSC) at 100kb\n",
    "        #17 = Intersects \"Other\" Refseq Genes (from UCSC) at 0kb\n",
    "        #18=Intersects with an FST CDR (default = False)\n",
    "        #19=Intersects with an XP-CLR CDR (default = False)\n",
    "        #20=Intersects with an VST VCDR (default = False) \n",
    "        #21=Intersects with an Axelsson FST CDR (default = False)\n",
    "        \n",
    "        #Did this ERV intersect with a gene?\n",
    "        index = 5 #len(ensGDict.keys())\n",
    "        if WinID in ensGDict: #If this window is in the ensembl list you generated, then...:\n",
    "            for num in range(0,index+1):\n",
    "                added = []\n",
    "                if len(ensGDict[WinID][num]) > 0:\n",
    "                    if ensGDict[WinID][num] not in added:\n",
    "                        y = \", \".join(map(str, ensGDict[WinID][num])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "                        allDict[WinID][5+num] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "                        added.append(ensGDict[WinID][num])\n",
    "                        b2goGenes.append(ensGDict[WinID][num])\n",
    "        #Did this ERV window intersect with an Dog ESTs?\n",
    "        if WinID in estDict: #If this window is in the ensembl list you generated, then...:\n",
    "            for num in range(0,index+1):\n",
    "                added = []\n",
    "                if len(estDict[WinID][num]) > 0:\n",
    "                    if ensGDict[WinID][num] not in added:\n",
    "                        y = \", \".join(map(str, estDict[WinID][num])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "                        allDict[WinID][11+num] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "                        added.append(ensGDict[WinID][num])\n",
    "                        \n",
    "        #Did this ERV window intersect with an \"OTHER\" RefSeq gene?\n",
    "        if WinID in otherDict: #If this window is in the ensembl list you generated, then...:\n",
    "            y = \", \".join(map(str, otherDict[WinID])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "            allDict[WinID][17] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "            \n",
    "        #SELECTION SCAN RESULTS    \n",
    "        #Did this ERV window intersect with a FST CDR?\n",
    "        if WinID in cdrDict: #If this window is in the ensembl list you generated, then...:\n",
    "            y = \", \".join(map(str, cdrDict[WinID])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "            allDict[WinID][18] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "        #Did this ERV window intersect with a XP-CLR CDR?\n",
    "        if WinID in xpclrDict: #If this window is in the ensembl list you generated, then...:\n",
    "            y = \", \".join(map(str, xpclrDict[WinID])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "            allDict[WinID][19] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "        #Did this ERV window intersect with a VST VCDR?\n",
    "        if WinID in vcdrDict: #If this window is in the ensembl list you generated, then...:\n",
    "            y = \", \".join(map(str, vcdrDict[WinID])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "            allDict[WinID][20] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "        #Did this ERV window intersect with a Axelsson FST Sweep?\n",
    "        if WinID in axDict: #If this window is in the ensembl list you generated, then...:\n",
    "            y = \", \".join(map(str, axDict[WinID])) #This takes the list you generated from the Ensembl file and joins each entry in the list with a comma\n",
    "            allDict[WinID][21] = y #Now it adds 'y' you generated in the line above to your dictionary\n",
    "   \n",
    "\n",
    "    #Writing out results\n",
    "    for keys in sorted(allDict.keys()): #Now loops through each \n",
    "        outFile.write(\"\\t\".join(map(str,allDict[keys])))\n",
    "        outFile.write(\"\\n\")\n",
    "    outFile.close()\n",
    "    inFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ampend/links/kidd-lab/ampend-projects/cfERVs/input/cfERV_NonReferenceInsertionSites_2017-06-29.bed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'b2goGenes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-63d142a09036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#MAKING SUMMARY FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmaking_summary_text_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mervDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mervfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensGDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0motherDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvcdrDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxpclrDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d13c2169e257>\u001b[0m in \u001b[0;36mmaking_summary_text_files\u001b[0;34m(ervDir, Type, ervfile, ensGDict, otherDict, estDict, vcdrDict, xpclrDict, axDict)\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mallDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWinID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;31m#Now it adds 'y' you generated in the line above to your dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0madded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensGDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWinID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                         \u001b[0mb2goGenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensGDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWinID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m#Did this ERV window intersect with an Dog ESTs?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mWinID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestDict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#If this window is in the ensembl list you generated, then...:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b2goGenes' is not defined"
     ]
    }
   ],
   "source": [
    "for ervfile in bedfiles:\n",
    "    if 'NonReference' in ervfile:\n",
    "        Type = 'NonReference'\n",
    "    else:\n",
    "        Type = 'Reference'\n",
    "    print(ervfile)\n",
    "    #ervfile = '/home/ampend/links/kidd-lab/ampend-projects/cfERVs/input/cfERV_NonReferenceInsertionSites_2017-06-29.bed'\n",
    "    ervDir = '/home/ampend/links/kidd-lab/ampend-projects/cfERVs/Insertion_Assessment/'\n",
    "\n",
    "    ###Selective Sweep Intersects\n",
    "    windowSize = int(50000)\n",
    "    #Get CDR intersects -- save to Dict\n",
    "    cdrfile = '/home/ampend/links/kidd-lab/ampend-projects/Angela/Re-RunningAnalysis_NewScripts/FINAL_results/MergedOverlapping_Sliding_TotalSIGFstCalls_AutoXPar_54callset.bed'\n",
    "    outfile = ervDir + 'results/' + '%ibp_Intersect_%sERVs_with_CDRs_SimulationThreshold.txt' % (windowSize, Type)\n",
    "    do_window_intersects(ervfile,cdrfile,int(windowSize),outfile)\n",
    "    cdrDict = process_intersect(outfile)\n",
    "    #Get VCDR intersects -- save to Dict\n",
    "    vcdrfile = '/home/ampend/links/kidd-lab/ampend-projects/Angela/Feichen_VST/FINAL_FILTERED_VCDR_SET/Filtered_VCDR.bed'\n",
    "    outfile = ervDir + 'results/' + '%ibp_Intersect_%s_with_VCDRs.txt'% (windowSize, Type)\n",
    "    do_window_intersects(ervfile,vcdrfile,int(windowSize),outfile)\n",
    "    vcdrDict = process_intersect(outfile)\n",
    "    #Get VCDR intersects -- save to Dict\n",
    "    xpclrfile = '/home/ampend/links/kidd-lab/ampend-projects/Angela/XP-CLR/results/Campbell_No-MAF-Filter/50kbWindow_2kbGrid/Dogs_v_Wolves/SignificantWindows/Significant_3Windows_pct99_AverageXP-CLRScore.4.bed'\n",
    "    outfile = ervDir + 'results/' + '%ibp_Intersect_%sERVs_with_XPCLR_SimulationThreshold.txt'% (windowSize, Type)\n",
    "    do_window_intersects(ervfile,xpclrfile,int(windowSize),outfile)\n",
    "    xpclrDict = process_intersect(outfile)\n",
    "    #Get Axelsson loci intersects -- save to Dict\n",
    "    axelssonBedFile = '/home/ampend/links/kidd-lab/ampend-projects/Angela/Re-RunningAnalysis_NewScripts/new_results/results/Axelsson_CaganBlass/input/Axelsson_canfam3.1.bed'\n",
    "    outfile = ervDir + 'results/' + '%ibp_Intersect_%sERVs_with_AxelssonCDRs_SimulationThreshold.txt'% (windowSize, Type)\n",
    "    do_window_intersects(ervfile,axelssonBedFile,int(windowSize),outfile)\n",
    "    axDict = process_intersect(outfile)\n",
    "\n",
    "    #Get ensembl gene intersects within window ranges -- save to Dict\n",
    "    windowSizes = ['0','5000','10000','25000','50000','100000']\n",
    "    index = 0\n",
    "    ensGDict = make_ensG_dict(ervfile)\n",
    "    for windowSize in windowSizes:\n",
    "        genebedfile = '/home/ampend/links/kidd-lab/ampend-projects/BLAST2GO/results/BLAST2GO_Ensembl81_GeneTables_WithEnscafIDsAndChrom.bed'\n",
    "        outfile = ervDir + 'results/' + str(windowSize) + 'bpWindowIntersect_%sERVs_with_EnsemblGenes.txt'% (Type)\n",
    "        do_window_intersects(ervfile,genebedfile,int(windowSize),outfile)\n",
    "        ensGDict = parse_gene_intersect_file(ensGDict,outfile,windowSize,index)\n",
    "        index+=1\n",
    "\n",
    "    #Intersecting and Parsing results with TransMap EST UCSC Track\n",
    "    index = 0\n",
    "    estDict = make_ensG_dict(ervfile)\n",
    "    for windowSize in windowSizes:\n",
    "        dogESTBedFile = '/home/ampend/links/kidd-lab/ampend-projects/cfERVs/GeneIntersects/dog_allESTs_CF3.bed'\n",
    "        outfile = ervDir + 'results/' + str(windowSize) + 'bpWindowIntersect_%sERVs_with_UCSCDogESTs_SimulationThreshold.txt'% (Type)\n",
    "        do_window_intersects(ervfile,dogESTBedFile,int(windowSize),outfile)\n",
    "        estDict = parse_gene_intersect_file(estDict,outfile,windowSize,index)\n",
    "        index+=1\n",
    "        \n",
    "    #5. Intersecting and Parsing results with \"Other\" RefSeq UCSC Track\n",
    "    otherRefSeqBedFile = '/home/ampend/links/kidd-lab/ampend-projects/cfERVs/GeneIntersects/other_refseq.bed'\n",
    "    outfile = ervDir + 'results/' + 'Intersect_%sERVs_with_OtherRefseqGenes_SimulationThreshold.txt'% (Type)\n",
    "    otherDict = do_intersects(ervfile, otherRefSeqBedFile, outfile)\n",
    "    \n",
    "    #MAKING SUMMARY FILE \n",
    "    making_summary_text_files(ervDir,Type,ervfile,ensGDict,otherDict,estDict,vcdrDict,xpclrDict,axDict)\n",
    "print('DONE!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLAST2GO - TOPGO PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b2goGenes = [] #for blast2go enrichment, kept at 50kb insertion distance\n",
    "for ervfile in bedfiles:\n",
    "    if 'NonReference' in ervfile:\n",
    "        Type = 'NonReference'\n",
    "    else:\n",
    "        Type = 'Reference'\n",
    "    print(Type)\n",
    "    outfile = ervDir + 'results/' + str(50000) + 'bpWindowIntersect_%sERVs_with_EnsemblGenes.txt'% (Type)\n",
    "    for line in open(outfile,'r'):\n",
    "        line = line.rstrip().split('\\t')\n",
    "        winID = line[3]\n",
    "        if '_' in line[7]:\n",
    "            hit = line[7].split('_')\n",
    "            Protein = hit[0]\n",
    "            Gene = hit[1]\n",
    "            b2goID = Gene + '|' + Protein\n",
    "            ensGID = hit[2]\n",
    "        b2goGenes.append(b2goID)\n",
    "b2goGeneFile = open(ervDir + 'results/' + 'ForTopGO_GenesWithin50kb_cfERVInsertion.txt','w')\n",
    "for i in range(0,len(b2goGenes)):\n",
    "    b2goGeneFile.write(b2goGenes[i] + '\\n')\n",
    "b2goGeneFile.close()\n",
    "print('Genes for TopGO enrichment saved here: ', b2goGeneFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TopGO prints out a list of genes per GO category that are enriched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "19856 genes read into gene-protein ID array\n"
     ]
    }
   ],
   "source": [
    "geneTable = '/home/ampend/links/kidd-lab/ampend-projects/BLAST2GO/results/BLAST2GO_GeneTables_WithEnscafIDsAndChrom.txt'\n",
    "#Saving gene-protein links that were processed with BLAST2GO to array\n",
    "TotEnsGene = {}\n",
    "\n",
    "for line in open(geneTable,'r'):\n",
    "    line = line.rstrip().split()\n",
    "    ensG,ensP,chrom,start,end,geneName = line[1],line[0],line[5],line[6],line[7],line[8]\n",
    "    TotEnsGene[ensG] = [ensG,ensP,chrom,start,end,geneName]\n",
    "print ('\\n%i genes read into gene-protein ID array' % len(TotEnsGene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 enriched gene categories added to topGoDict\n"
     ]
    }
   ],
   "source": [
    "topGOPvalueFile=ervDir + 'results/' + 'Total_cfERV_50kbWindowIntersect_EnrichmentTable_Pvalue0.05_ParentChild_BP_MF_CC.txt'\n",
    "topGODict={}\n",
    "for line in open(topGOPvalueFile,'r'):\n",
    "    line=line.rstrip().split('\\t')\n",
    "    if 'GO:' not in line[1]:\n",
    "        continue\n",
    "    GOID = line[1]\n",
    "    topGODict[GOID] = line\n",
    "print('%i enriched gene categories added to topGoDict' % len(topGODict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 insertions added to dictionary\n"
     ]
    }
   ],
   "source": [
    "types = ['Reference','NonReference']\n",
    "insDict = {}\n",
    "for Type in types:\n",
    "    intFile = ervDir + 'results/'  + '50000bpWindowIntersect_%sERVs_with_EnsemblGenes.txt' % (Type)\n",
    "    for line in open(intFile,'r'):\n",
    "        line=line.rstrip().split('\\t')\n",
    "        insertion = line[3]\n",
    "        longgene = line[7].split('_')\n",
    "        ensG = longgene[1]\n",
    "        insDict[ensG] = insertion\n",
    "print('%i insertions added to dictionary' % len(insDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_full_BLASTGO_category_names(ervDir):\n",
    "    fullgonames = ervDir + 'results/' + 'full_go_cat_names.txt'\n",
    "    nameDict = {}\n",
    "    for line in open(fullgonames,'r'):\n",
    "        line=line.rstrip().split('\\t')\n",
    "        if 'GO:' not in line[0]:\n",
    "            continue\n",
    "        nameDict[line[0]] = line[1]\n",
    "    return nameDict\n",
    "################################################################################################################\n",
    "def find_perfect_insertions(ervDir):\n",
    "    #list of genes that are 0kb insertions\n",
    "    perfInsFile = ervDir + 'results/' + 'perfect_gene_insertion_gene_list.txt'\n",
    "    perfIns = []\n",
    "    for line in open(perfInsFile,'r'):\n",
    "        line=line.rstrip().split('\\t')\n",
    "        perfIns.append(line[0])\n",
    "    print('%i genes with perfect cfERV insertions (0kb window) / intronic/exonic' % len(perfIns))\n",
    "    return perfIns\n",
    "################################################################################################################\n",
    "def get_humanphenotypes():\n",
    "    hpoFile = '/home/ampend/links/kidd-lab/ampend-projects/BLAST2GO/Human-Phenotype-Ontology/HPO_Oct2017Release_genes-to-phenotypes.txt'\n",
    "    hpoDict = {}\n",
    "    for line in open(hpoFile,'r'):\n",
    "        line=line.rstrip().split('\\t')\n",
    "        if '#' in line[0]: #skips header\n",
    "            continue\n",
    "        geneName, phenotype, HP = line[1], line[2], line[3]\n",
    "        if geneName not in hpoDict.keys():\n",
    "            hpoDict[geneName] = []\n",
    "        hpoDict[geneName].append([phenotype, HP])    \n",
    "    print('%i human phenotyped genes added to dictionary' % len(hpoDict))\n",
    "    return hpoDict\n",
    "################################################################################################################\n",
    "def make_ens_transcript_map_dict():\n",
    "    ensembl_MapFile = '/home/ampend/links/kidd-lab/ampend-projects/cfERVs/Insertion_Assessment/dog_Ensembl_EnsG_EnsP_EnsT_Map.txt'\n",
    "    enDict = {}\n",
    "    for line in open(ensembl_MapFile,'r'):\n",
    "        line=line.rstrip().split()\n",
    "        if '#' in line[0]: #skips header\n",
    "            continue\n",
    "        gene, enG, enT = line[1], line[2], line[0]\n",
    "        enG = enG.split('.')[0]\n",
    "        if enT not in enDict.keys():\n",
    "            enDict[enG]=[gene, enT]\n",
    "    print('%i genes added to enTDict' % len(enDict))\n",
    "    return enDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 genes with perfect cfERV insertions (0kb window) / intronic/exonic\n",
      "15548 genes added to enTDict\n",
      "3682 human phenotyped genes added to dictionary\n",
      "GO:0012505 29\n"
     ]
    }
   ],
   "source": [
    "outputs = ['cfERV_50KbWindowIntersect_EnrichmentTable_Pvalue=0.05_MF_TopGOOutput_ParentChild_Genes.txt','cfERV_50KbWindowIntersect_EnrichmentTable_Pvalue=0.05_CC_TopGOOutput_ParentChild_Genes.txt', 'cfERV_50KbWindowIntersect_EnrichmentTable_Pvalue=0.05_BP_TopGOOutput_ParentChild_Genes.txt']\n",
    "mergedOutFile = open(ervDir + 'results/' + 'AnnotatedTopGO_EnrichedGenes_50kbCfERVInsertions.txt','w')\n",
    "insGeneGODict = {}\n",
    "#Set-up inputs\n",
    "perfIns = find_perfect_insertions(ervDir)\n",
    "nameDict = get_full_BLASTGO_category_names(ervDir)\n",
    "enDict = make_ens_transcript_map_dict()\n",
    "hpoDict = get_humanphenotypes()\n",
    "\n",
    "#Now begin processing\n",
    "for topGoGeneFile in outputs:\n",
    "    topGoGeneFile = open(ervDir + 'results/' + topGoGeneFile,'r')\n",
    "    for line in topGoGeneFile:\n",
    "        line=line.replace('\"','')\n",
    "        line=line.rstrip().split(' ')\n",
    "        if 'GO:' not in line[0]: #skips headers\n",
    "            continue\n",
    "        GOID = line[0]\n",
    "        geneLists = line[1]\n",
    "        genes = geneLists.split(',')\n",
    "        topGOInfo = topGODict[GOID]\n",
    "        topGOInfo[2] = nameDict[GOID]\n",
    "        genomeCount, setCount, pvalue1,pvalue2 =  topGOInfo[3],topGOInfo[4],float(topGOInfo[8]),float(topGOInfo[9])\n",
    "        for i in range(0,len(topGOInfo)):\n",
    "            mergedOutFile.write('%s\\t' % topGOInfo[i])\n",
    "        #What genes are annotated for this GO category\n",
    "        ensGList, insList, geneNames, count = [], [], [], 0\n",
    "        uniqueInsertionList = [] #Clear to keep track of how many unique insertions are found for this category\n",
    "        for gene in genes:\n",
    "            ensG,engP = gene.split('|')[0],gene.split('|')[1]\n",
    "            ensGList.append(ensG)\n",
    "            #info = [TotEnsGene[ensG][2],TotEnsGene[ensG][3],TotEnsGene[ensG][4],TotEnsGene[ensG][5]]\n",
    "            #What insertions do these correspond to\n",
    "            insertion = insDict[ensG]\n",
    "            insList.append(insertion)\n",
    "            geneName = TotEnsGene[ensG][5]\n",
    "            geneNames.append(geneName)\n",
    "            if insertion not in uniqueInsertionList:\n",
    "                uniqueInsertionList.append(insertion)\n",
    "            if geneName in perfIns:\n",
    "                if GOID not in insGeneGODict.keys():\n",
    "                    #0 = go description, #1 total gene count enriched #2 perf insertion count\n",
    "                    #3 = gene names for perf ins, #4 = insertion IDs for perfect insertions\n",
    "                    insGeneGODict[GOID] = [nameDict[GOID],genomeCount,setCount,'geneInsertionCount',pvalue1,pvalue2,[],[],0]\n",
    "                insGeneGODict[GOID][6].append(geneName)\n",
    "                insGeneGODict[GOID][7].append(insertion)\n",
    "                count+=1\n",
    "        y = \", \".join(map(str, ensGList))\n",
    "        mergedOutFile.write('%s\\t' % (y))\n",
    "        y = \", \".join(map(str, geneNames))\n",
    "        mergedOutFile.write('%s\\t' % (y))\n",
    "        y = \", \".join(map(str, insList))\n",
    "        mergedOutFile.write('%s\\t' % (y))\n",
    "        #Number of Unique insertions\n",
    "        mergedOutFile.write('%i\\n' % (len(uniqueInsertionList)))\n",
    "        if GOID in insGeneGODict.keys():        \n",
    "            #Keeping track of information for the perfect insertions\n",
    "            #insGeneGODict[GOID][5] = int(len(ensGList))\n",
    "            insGeneGODict[GOID][3] = count\n",
    "            insGeneGODict[GOID][8] = len(uniqueInsertionList)\n",
    "            if '12505' in GOID:\n",
    "                print(GOID,len(uniqueInsertionList))\n",
    "\n",
    "mergedOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perfInsertionGOFile = open(ervDir + 'results/' + 'GoAnnotations_PerfectInsertions_CountsTable.txt','w')\n",
    "header = 'GO ID\\tGO Description\\tGenes in GO Category in Genome\\tGenes in GO Category in cfERV set\\tGenes in GO Category in Perfect Gene Insertion Set\\tTopGO Fisher P-Value\\tParent-Child Fisher P-Value\\tGenes\\tInsertions\\tUnique Insertions Represented\\n'\n",
    "perfInsertionGOFile.write('%s\\n' % header)\n",
    "for GOID in insGeneGODict.keys():\n",
    "    info = insGeneGODict[GOID]\n",
    "    name, genomeCount, setCount, geneInsertionCount = info[0:4] \n",
    "    topgoP, parentP,uniqueInsertions = float(info[4]),float(info[5]),info[8]\n",
    "    genes = info[6]\n",
    "    for i in genes:\n",
    "        y = \", \".join(map(str, genes))\n",
    "    insertions = info[7]\n",
    "    for j in insertions:\n",
    "        z = \", \".join(map(str, insertions))\n",
    "    perfInsertionGOFile.write('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n' % (GOID,name, genomeCount, setCount, geneInsertionCount, topgoP, parentP, y, z, uniqueInsertions))\n",
    "perfInsertionGOFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Human-Phenotype Ontology Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phenotype_for_gene(geneName,intHPODict,hpoDict,humanPhenotypeLinkFile):\n",
    "    for i in range(0,len(hpoDict[geneName])):\n",
    "        phenotype, HPID = hpoDict[geneName][i][0],hpoDict[geneName][i][1]\n",
    "        #Write total results to an out file\n",
    "        humanPhenotypeLinkFile.write('%s\\t%s\\t%s\\t%s\\n' % (geneName, insertion,phenotype, HPID ))\n",
    "        #but keep track of the number of instances you see a certain phenotype\n",
    "        if HPID not in intHPODict.keys():\n",
    "            intHPODict[HPID] = []\n",
    "        intHPODict[HPID].append([phenotype,insertion,geneName])\n",
    "    return intHPODict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intHPODict = {}\n",
    "humanPhenotypeLinkFile = open(ervDir + 'results/' + 'HumanPhenotypeOntology_cfERV50kbWindowInsertions_AnnotationTable.txt', 'w')\n",
    "processed = []\n",
    "\n",
    "#Now begin processing\n",
    "for topGoGeneFile in outputs:\n",
    "    topGoGeneFile = open(ervDir + 'results/' + topGoGeneFile,'r')\n",
    "    for line in topGoGeneFile:\n",
    "        line=line.replace('\"','')\n",
    "        line=line.rstrip().split(' ')\n",
    "        if 'GO:' not in line[0]: #skips headers\n",
    "            continue\n",
    "        GOID = line[0]\n",
    "        geneLists = line[1]\n",
    "        genes = geneLists.split(',')\n",
    "        #What genes are annotated for this GO category\n",
    "        for gene in genes:\n",
    "            ensG,ensP = gene.split('|')[0],gene.split('|')[1]\n",
    "            #What insertions do these correspond to\n",
    "            insertion = insDict[ensG]\n",
    "            #What is the full gene name?\n",
    "            geneName = TotEnsGene[ensG][5]\n",
    "            if geneName not in processed:\n",
    "                processed.append(geneName)\n",
    "            else:\n",
    "                continue\n",
    "            if geneName in hpoDict.keys():\n",
    "                intHPODict = get_phenotype_for_gene(geneName,intHPODict,hpoDict,humanPhenotypeLinkFile)\n",
    "            else:\n",
    "                if ensG in enDict.keys():\n",
    "                    geneName = enDict[ensG][0]\n",
    "                    if geneName in hpoDict.keys():\n",
    "                        intHPODict = get_phenotype_for_gene(geneName,intHPODict,hpoDict,humanPhenotypeLinkFile)\n",
    "                else:\n",
    "                    continue\n",
    "humanPhenotypeLinkFile.close()      \n",
    "\n",
    "summaryFile = open(ervDir + 'results/' + 'summary_morethan2_hpo_table.txt','w')\n",
    "for HPID in intHPODict.keys():\n",
    "    if len(intHPODict[HPID]) >= 2:\n",
    "        summaryFile.write('%s\\t%s\\t%s\\t' % (HPID,str(len(intHPODict[HPID])),str(intHPODict[HPID][0][0])))\n",
    "        for i in range(0,len(intHPODict[HPID])):\n",
    "            insert, gene = intHPODict[HPID][i][1], intHPODict[HPID][i][2]\n",
    "            summaryFile.write('%s (%s)\\t' % (insert, gene))\n",
    "        summaryFile.write('\\n')\n",
    "summaryFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
