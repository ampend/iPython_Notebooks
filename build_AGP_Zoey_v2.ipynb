{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2017-05-08\n",
    "#A. Pendleton\n",
    "#This script is used to make an AGP file for Zoey. It incoporates the coordinates for filled gaps \n",
    "#   determined by Feichen's script for assembling PacBio reads at the junctions of contig gaps.\n",
    "\n",
    "#this uses iPython magic to make plots appear inline\n",
    "%matplotlib inline\n",
    "import subprocess\n",
    "\n",
    "#import genutils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This script is used to make an AGP file to build Zoey v2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHROM = 'chr18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is:\n",
      " /home/ampend/links/kidd-lab/ampend-projects/Zoey_Genome_Project/AGP/\n"
     ]
    }
   ],
   "source": [
    "wkDir = '/home/ampend/links/kidd-lab/ampend-projects/Zoey_Genome_Project/AGP/'\n",
    "print('Current working directory is:\\n', wkDir)\n",
    "\n",
    "logFile = open(wkDir + 'temp/iPythonNotebook_LogFile_' + CHROM + '_v2.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified coordinates for 77 primary contigs on chr18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####READING IN PRIMARY CONTIG COORDINATES FROM MUMMER ALIGNMENT#######\n",
    "#Primary contig alignments (no canu processing)\n",
    "primaryContigCoord = open(wkDir + 'input/primary.2017-04-10.txt', 'r')\n",
    "primaryContigCoordBed = open(wkDir + 'input/primary.2017-04-10_' + CHROM +'v2.bed', 'w')\n",
    "\n",
    "contigDict,index = {}, 0\n",
    "\n",
    "for line in primaryContigCoord:\n",
    "    if line.startswith(\"#\") is True: #skips header line\n",
    "        continue\n",
    "    line = line.rstrip().split('\\t')\n",
    "    contigID, length, Dir, chrom, start, end = line[0],line[1],line[2],line[3],int(line[4]),int(line[5])    \n",
    "    if CHROM not in chrom: #FILTERING ONLY FOR CHROM 18 FOR NOW!!! REMOVE LATER \n",
    "        continue\n",
    "    index += 1\n",
    "    contigDict[index] = [chrom,start,end,contigID,Dir,length]\n",
    "    primaryContigCoordBed.write('%s\\t%i\\t%i\\t%s\\n' % (chrom,int(start-1),end,contigID))\n",
    "    #if index > 15: #FOR TESTING--- REMOVE LATER\n",
    "    #    break\n",
    "    \n",
    "primaryContigCoord.close()\n",
    "primaryContigCoordBed.close()\n",
    "print ('Identified coordinates for %i primary contigs on %s' % (len(contigDict), CHROM))\n",
    "logFile.write('Identified coordinates for %i primary contigs on %s' % (len(contigDict), CHROM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Read in coordinates from alignment file based on Mummer of primary contigs (per Jeff)\n",
    "Step 2. BLAT each contig against the contig proximal to that proximal to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_line(Dict,curr_index,i):\n",
    "    #Contig 1\n",
    "    chrom1,start1,end1,contigID1,Dir1,length1 = Dict[curr_index][0],int(Dict[curr_index][1]),int(Dict[curr_index][2]), Dict[curr_index][3], Dict[curr_index][4], int(Dict[curr_index][5])\n",
    "    #Contig 2\n",
    "    chrom2,start2,end2,contigID2,Dir2,length2 = Dict[i+1][0],int(Dict[i+1][1]),int(Dict[i+1][2]), Dict[i+1][3], Dict[i+1][4], int(Dict[i+1][5])\n",
    "    return chrom1,start1,end1,contigID1,Dir1,length1,chrom2,start2,end2,contigID2,Dir2,length2\n",
    "###################################################################################################\n",
    "def read_last_line(Dict):\n",
    "    #Contig 1\n",
    "    chrom1,start1,end1,contigID1,Dir1,length1 = Dict[i-1][0],int(Dict[i-1][1]),int(Dict[i-1][2]), Dict[i-1][3], Dict[i-1][4], int(Dict[i-1][5])\n",
    "    #Contig 2\n",
    "    chrom2,start2,end2,contigID2,Dir2,length2 = Dict[i][0],int(Dict[i][1]),int(Dict[i][2]), Dict[i][3], Dict[i][4], int(Dict[i][5])\n",
    "    return chrom1,start1,end1,contigID1,Dir1,length1,chrom2,start2,end2,contigID2,Dir2,length2\n",
    "###################################################################################################\n",
    "def process_last_contig(contigDict,curr_index,i):\n",
    "    chrom1,start1,end1,contigID1,Dir1,length1,chrom2,start2,end2,contigID2,Dir2,length2 = read_last_line(contigDict)\n",
    "    #print ('\\n#%s (%i) -- %s (%i)' % (contigID1,i-1,contigID2,i))\n",
    "    logFile.write(('\\n#%s (%i) -- %s (%i)\\n' % (contigID1,i-1,contigID2,i)))\n",
    "    if start1 == start2 or end1 == end2:\n",
    "        return\n",
    "    if end2 > end1:\n",
    "        curr_index+=1 \n",
    "        curated_contigDict[i] = [chrom2,start2,end2,contigID2,Dir2,length2]\n",
    "        inList.append(contigID2)\n",
    "        #print('PASS - Last contig on chromosome overlap or is spaced correctly')\n",
    "        logFile.write('PASS - Last contig on chromosome overlap or is spaced correctly\\n')\n",
    "        return\n",
    "###################################################################################################\n",
    "def process_first_contig(contigDict,curr_index,i):\n",
    "    curr_index+=1\n",
    "    #Always save first and contig in the dictionary/dataset\n",
    "    curated_contigDict[i] = [chrom1,start1,end1,contigID1,Dir1,length1]\n",
    "    curated_contigDict[i+1] = [chrom2,start2,end2,contigID2,Dir2,length2]\n",
    "    inList.append(contigID2)\n",
    "    #print('PASS - First call in dataset')\n",
    "    logFile.write('PASS - First call in dataset\\n')\n",
    "    return curr_index \n",
    "###################################################################################################\n",
    "def process_same_starts(contigDict,curr_index,i):\n",
    "    if start1 == start2 and end1 > end2:\n",
    "        #print('FAIL -- Share start, contig1 longer' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]))\n",
    "        logFile.write('FAIL -- Share start, contig1 longer' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]) + '\\n')\n",
    "        return\n",
    "    if start1 == start2 and end1 < end2: #overwrite previous position if contig 2 is longer than contig 1\n",
    "        curated_contigDict[i] = [chrom2,start2,end2,contigID2,Dir2,length2]\n",
    "        #print('FAIL -- Share start, contig2 longer' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]))\n",
    "        logFile.write('FAIL -- Share start, contig2 longer' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]) + '\\n')\n",
    "        return\n",
    "###################################################################################################\n",
    "def process_same_ends(contigDict,curr_index,i):    \n",
    "    if start1 < start2 and end1 == end2:\n",
    "        #print('Ends same, kept contig 1 only' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]))\n",
    "        logFile.write('Ends same, kept contig 1 only' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]) + '\\n')\n",
    "        return \n",
    "    if start2 < start1 and end1 == end2: \n",
    "        print('ERROR - is this contig list sorted??!!')\n",
    "        logFile.write('ERROR - is this contig list sorted??!!\\n\\n\\n')\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "curated_contigDict, curr_index, inList = {}, 1, []\n",
    "chrom1,chrom2 = '0', '0' #initializing values\n",
    "\n",
    "\n",
    "for key, value in contigDict.items(): \n",
    "    i = int(key)\n",
    "    #1. If last contig in dataset \n",
    "    if i == len(contigDict):\n",
    "        continue\n",
    "    \n",
    "    #2. If contigs are on different chromosomes:\n",
    "    if chrom1 != chrom2:\n",
    "        process_last_contig(contigDict,curr_index,i)\n",
    "        continue\n",
    "        \n",
    "    chrom1,start1,end1,contigID1,Dir1,length1,chrom2,start2,end2,contigID2,Dir2,length2 = read_line(contigDict,curr_index,i)\n",
    "    #print ('\\n#%s (%i) -- %s (%i)' % (contigID1,curr_index,contigID2,i+1))\n",
    "    logFile.write('\\n#%s (%i) -- %s (%i)\\n' % (contigID1,curr_index,contigID2,i+1))\n",
    "\n",
    "    #3. Automatically saves first contig in dataset\n",
    "    if curr_index == 1 and len(curated_contigDict) == 0:\n",
    "        curr_index = process_first_contig(contigDict,curr_index,i)\n",
    "        continue\n",
    "    \n",
    "    #4. If contigs have the same start site, choose the longest contig\n",
    "    if start1 == start2:\n",
    "        process_same_starts(contigDict,curr_index,i)\n",
    "        continue\n",
    "\n",
    "    #5. If contigs have same end coordinate, choose longest contig (i.e. contig #1 if sorted)\n",
    "    if end1 == end2: \n",
    "        process_same_ends(contigDict,curr_index,i)\n",
    "        continue\n",
    "        \n",
    "    #6. If contigs #1 and #2 have same start AND end, keep contig #1\n",
    "    if start1 == start2 and end1 == end2:\n",
    "        #print('FAIL -- Same start and end coordinate' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]))\n",
    "        logFile.write('FAIL -- Same start and end coordinate' + '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]) + '\\n')\n",
    "        continue #because contig1 is already in the dictionary\n",
    "        \n",
    "    #7. If contig #2 is fully within contig #1 -- continue\n",
    "    if start1 < start2 and end1 > end2: # contig2 is fully within contig1\n",
    "        #curated_contigDict[curr_index] = [chrom1,start1,end1,contigID1,Dir1,length1]\n",
    "        #print('FAIL -- Contig2 fully within contig1' + '\\nKeeping contig: ' + contigID1 +  '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]))\n",
    "        logFile.write('FAIL -- Contig2 fully within contig1' + '\\nKeeping contig: ' + contigID1 +  '\\n' + str(contigDict[i]) + '\\n' + str(contigDict[i+1]) +'\\n')\n",
    "        continue\n",
    "    if start1 > start2 and end1 < end2:\n",
    "        #print('ERROR - is this contig list sorted??!!')\n",
    "        logFile.write('ERROR - is this contig list sorted??!!\\n\\n\\n')\n",
    "        sys.exit(1)\n",
    "    \n",
    "    #8. If contig passes all these - then automatically saves\n",
    "    curr_index=i+1\n",
    "    #if contigID2 not in inList:\n",
    "    curated_contigDict[i] = [chrom2,start2,end2,contigID2,Dir2,length2]\n",
    "    #print('PASS - contigs overlap or are spaced correctly')\n",
    "    logFile.write('PASS - contigs overlap or are spaced correctly\\n')\n",
    "\n",
    "#print ('Identified CURATED coordinates for %i primary contigs' % len(curated_contigDict))\n",
    "logFile.write('\\n##Identified CURATED coordinates for %i primary contigs\\n\\n########\\n\\n' % len(curated_contigDict))\n",
    "\n",
    "\n",
    "#Re-naming dictionary keys\n",
    "count=0\n",
    "for keys in curated_contigDict:\n",
    "    count+=1\n",
    "    curated_contigDict[count]=curated_contigDict.pop(keys)\n",
    "\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Curated:\n",
      "1 ['chr18', 2619, 26992, 'CTG-1462', 'rc', 24712]\n",
      "2 ['chr18', 22143, 3966426, 'CTG-0201', 'rc', 3968428]\n",
      "3 ['chr18', 3964697, 3978047, 'CTG-1861', 'fwd', 13154]\n",
      "4 ['chr18', 3975410, 4660269, 'CTG-0743', 'fwd', 681475]\n",
      "5 ['chr18', 4634379, 5281622, 'CTG-0770', 'rc', 639396]\n",
      "6 ['chr18', 5260259, 9645181, 'CTG-0177', 'rc', 4363384]\n",
      "7 ['chr18', 9638686, 10286737, 'CTG-0767', 'rc', 647068]\n",
      "8 ['chr18', 10284678, 11357644, 'CTG-0615', 'rc', 1078170]\n",
      "9 ['chr18', 11320457, 11367174, 'CTG-1278', 'fwd', 37673]\n",
      "10 ['chr18', 11326266, 13501863, 'CTG-0400', 'rc', 2190587]\n",
      "11 ['chr18', 13506715, 14852995, 'CTG-0564', 'rc', 1349347]\n",
      "12 ['chr18', 14854286, 17956069, 'CTG-0274', 'rc', 3082702]\n",
      "13 ['chr18', 17965033, 18359454, 'CTG-0878', 'rc', 395029]\n",
      "14 ['chr18', 18389873, 18474563, 'CTG-1134', 'fwd', 85495]\n",
      "15 ['chr18', 18470534, 18504760, 'CTG-1314', 'fwd', 34113]\n",
      "16 ['chr18', 18491492, 18506121, 'CTG-1776', 'rc', 14596]\n",
      "17 ['chr18', 18504761, 18543987, 'CTG-1294', 'fwd', 38857]\n",
      "18 ['chr18', 18588316, 19084754, 'CTG-0810', 'rc', 490363]\n",
      "19 ['chr18', 19091924, 19366433, 'CTG-0953', 'rc', 273581]\n",
      "20 ['chr18', 19367948, 20648758, 'CTG-0581', 'fwd', 1280510]\n",
      "21 ['chr18', 20635138, 20993149, 'CTG-0901', 'rc', 355818]\n",
      "22 ['chr18', 21000805, 22654130, 'CTG-0483', 'rc', 1655346]\n",
      "23 ['chr18', 22629484, 23228962, 'CTG-0776', 'rc', 597680]\n",
      "24 ['chr18', 23214064, 25317843, 'CTG-0412', 'rc', 2106211]\n",
      "25 ['chr18', 25332110, 26328164, 'CTG-0630', 'fwd', 1034698]\n",
      "26 ['chr18', 26307857, 26340773, 'CTG-1329', 'rc', 32757]\n",
      "27 ['chr18', 26349001, 28160518, 'CTG-0458', 'fwd', 1814553]\n",
      "28 ['chr18', 28162676, 30223054, 'CTG-0416', 'rc', 2045472]\n",
      "29 ['chr18', 30217866, 30259696, 'CTG-1241', 'rc', 47540]\n",
      "30 ['chr18', 30248555, 30591231, 'CTG-0907', 'rc', 349004]\n",
      "31 ['chr18', 30609502, 34128003, 'CTG-0235', 'fwd', 3508078]\n",
      "32 ['chr18', 34117531, 36616051, 'CTG-0351', 'rc', 2534292]\n",
      "33 ['chr18', 36629602, 37366888, 'CTG-0725', 'fwd', 736753]\n",
      "34 ['chr18', 37418531, 39290284, 'CTG-0432', 'fwd', 1950806]\n",
      "35 ['chr18', 39276368, 39312643, 'CTG-1297', 'rc', 35966]\n",
      "36 ['chr18', 39326301, 39981535, 'CTG-0756', 'fwd', 668698]\n",
      "37 ['chr18', 39965281, 40427697, 'CTG-0835', 'fwd', 450689]\n",
      "38 ['chr18', 40430282, 40438128, 'CTG-2129', 'rc', 7821]\n",
      "39 ['chr18', 40529539, 41359396, 'CTG-0720', 'fwd', 738619]\n",
      "40 ['chr18', 41341524, 41503975, 'CTG-1048', 'fwd', 164381]\n",
      "41 ['chr18', 41493766, 41997929, 'CTG-0817', 'rc', 504439]\n",
      "42 ['chr18', 42004148, 45129980, 'CTG-0272', 'fwd', 3124127]\n",
      "43 ['chr18', 45145223, 45362298, 'CTG-0989', 'fwd', 216468]\n",
      "44 ['chr18', 45367792, 49109540, 'CTG-0213', 'fwd', 3736794]\n",
      "45 ['chr18', 49083545, 49130813, 'CTG-1240', 'rc', 47251]\n",
      "46 ['chr18', 49096510, 49548067, 'CTG-0854', 'fwd', 454291]\n",
      "47 ['chr18', 49552106, 49746838, 'CTG-1000', 'fwd', 194595]\n",
      "48 ['chr18', 49746839, 52779109, 'CTG-0282', 'fwd', 3034721]\n",
      "49 ['chr18', 52768748, 53825339, 'CTG-0620', 'rc', 1057651]\n",
      "50 ['chr18', 53834389, 55739311, 'CTG-0459', 'rc', 1823704]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print('Non-curated:')\n",
    "for i in contigDict:\n",
    "    print(i,contigDict[i])\"\"\"\n",
    "#\"\"\"\n",
    "print( '\\nCurated:')\n",
    "for i in curated_contigDict:\n",
    "    print(i, curated_contigDict[i])\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_first_contig_on_chrom(chrom1,start1,end1,contigID1,Dir1,length1):\n",
    "    chrom2 = chrom1\n",
    "    start2 = start1 - 10000\n",
    "    end2 = start1 + 10000\n",
    "    contigID2 = 'canFam3'\n",
    "    Dir2 = 'fwd'\n",
    "    length1 = end2-start2\n",
    "    \n",
    "    if start2 < 0:\n",
    "        start2 = 0\n",
    "    \n",
    "    #Determine overlap \n",
    "    determine_contig_overlap(end1, contigID1, Dir1, length1, end2, contigID2, Dir2, length2)\n",
    " \n",
    "    #Find coordinates to extract\n",
    "    find_overlapping_coordinates(overlap,end1, contigID1, Dir1, length1, end2, contigID2, Dir2, length2)\n",
    "    \n",
    "    #Extract FASTA\n",
    "    fastaRoot = '/home/ampend/links/kidd-lab/genomes/canFam3.1/'\n",
    "    extract_fasta(fastaRoot,contigID1,Dir1,extract_coord1,contigID2,Dir2,extract_coord2)\n",
    "###################################################################################################\n",
    "def determine_contig_overlap(end1, contigID1, Dir1, length1, end2, contigID2, Dir2, length2):\n",
    "    #How much do the contigs overlap?\n",
    "    global overlap\n",
    "    overlap = end1 - start2\n",
    "    #print('\\nOverlap = ', overlap)\n",
    "    #OVERLAPPING CONTIGS\n",
    "    if overlap > 0:\n",
    "        find_overlapping_coordinates(overlap,end1, contigID1, Dir1, length1, end2, contigID2, Dir2, length2)\n",
    "    #DIRECTLY ADJACENT CONTIGS\n",
    "    if overlap == 0:\n",
    "        #print('Contigs are directly adjacent to one another')\n",
    "        logFile.write('Contigs are directly adjacent to one another\\n')\n",
    "        #WRITE FUNCTION FOR THESE\n",
    "    #CONTIGS WITH GAP BETWEEN THEM\n",
    "    if overlap < 0:\n",
    "        #print('Gap between contigs')\n",
    "        logFile.write('Gap between contigs\\n')\n",
    "\n",
    "###################################################################################################\n",
    "def find_overlapping_coordinates(overlap,end1, contigID1, Dir1, length1, end2, contigID2, Dir2, length2):\n",
    "    ###Determine coordinates to extract for BLAT\n",
    "    global extract_coord1\n",
    "    global extract_coord2\n",
    "    #Contig #1\n",
    "    if 'fwd' in Dir1:\n",
    "        extract_coord1 = [length1 - overlap - 10000, length1]\n",
    "    else:\n",
    "        extract_coord1 = [0, overlap + 10000]\n",
    "    #Contig #2\n",
    "    if 'fwd' in Dir2:\n",
    "        extract_coord2 = [0, overlap + 10000] \n",
    "    else:\n",
    "        extract_coord2 = [length2 - overlap - 10000, length2]\n",
    "    \n",
    "    #print ('Coordinates to extract for BLAT: ',extract_coord1,extract_coord2,'\\n')\n",
    "    logFile.write('Coordinates to extract for BLAT: ' + str(extract_coord1) + str(extract_coord2) + '\\n')\n",
    "\n",
    "    #safety check\n",
    "    for i in range(0,1): #CHECKS \n",
    "        #= if the region to extract extends beyond the length of the contig, if so then the coordinate changes to the length of contig\n",
    "        if extract_coord1[i] > length1:\n",
    "            extract_coord1[i] = length1\n",
    "        if extract_coord2[i] > length2:\n",
    "            extract_coord2[i] = length2\n",
    "        # If the region extended too far, and the value is negative -- then make starting extraction coordinate = 0\n",
    "        if extract_coord1[i] < 0: \n",
    "            extract_coord1[i] = 0\n",
    "        if extract_coord2[i] < 0:\n",
    "            extract_coord2[i] = 0\n",
    "            \n",
    "    if overlap < 0: #### SEND TO DIFFERENT FUNCTION LATER -- FOLLOW OVERLAPPING CONTIGS FOR NOW\n",
    "        #print('Contigs do not overlap')\n",
    "        logFile.write('Contigs do not overlap\\n')\n",
    "    #Where to find fasta of contigs\n",
    "    fastaRoot = '/home/ampend/links/kidd-lab/jmkidd-projects/zoey/contig-assignment/kmer-matches/eval1/'\n",
    "    extract_fasta(fastaRoot,contigID1,Dir1,extract_coord1, contigID2,Dir2,extract_coord2)\n",
    "    \n",
    "###################################################################################################\n",
    "def extract_fasta(fastaRoot,contigID1,Dir1,extract_coord1,contigID2,Dir2,extract_coord2):\n",
    "    #Contig 1\n",
    "    fasta_path1 = fastaRoot + contigID1 + '/' + contigID1 + '.fa'\n",
    "    cmd = 'samtools faidx %s %s:%i-%i  > %stemp/contig1.fa' % (fasta_path1,contigID1,extract_coord1[0],extract_coord1[1],wkDir)\n",
    "    logFile.write(cmd + '\\n')\n",
    "    subprocess.call(cmd,shell=True)\n",
    "    \n",
    "    #Contig 2\n",
    "    fasta_path2 = fastaRoot + contigID2 + '/' + contigID2 + '.fa'\n",
    "    cmd = 'samtools faidx %s %s:%i-%i > %stemp/contig2.fa' % (fasta_path2,contigID2,extract_coord2[0],extract_coord2[1],wkDir)\n",
    "    logFile.write(cmd + '\\n')\n",
    "    subprocess.call(cmd,shell=True)\n",
    "    \n",
    "###################################################################################################\n",
    "def run_blat(wkDir):\n",
    "    blatcmd = 'blat %stemp/contig1.fa %stemp/contig2.fa %stemp/temp.blat' % (wkDir,wkDir,wkDir)\n",
    "    logFile.write(blatcmd + '\\n')\n",
    "    subprocess.call(blatcmd,shell=True)\n",
    "    \n",
    "    \n",
    "###################################################################################################\n",
    "def parse_blat(wkDir,overlap,contigID1,Dir1,extract_coord1,contigID2,Dir2,extract_coord2):\n",
    "    inFile = open('%stemp/temp.blat' % (wkDir),'r')\n",
    "    lineCount, cleanAlignment, offset = 0, False, 0\n",
    "    for line in inFile:\n",
    "        line=line.rstrip().split('\\t')\n",
    "        lineCount+=1\n",
    "        if lineCount > 5:#skips the BLAT results headers\n",
    "            score,strand = int(line[0]),line[8]\n",
    "            percent_of_overlap = float(score)/overlap\n",
    "            if percent_of_overlap < float(0.75):\n",
    "                continue\n",
    "            #print('\\n#Parsing BLAT results','Percent of overlap matched in BLAT: ',format(percent_of_overlap, '.3f'))\n",
    "            logFile.write('\\n#Parsing BLAT results\\n' + 'Percent of overlap matched in BLAT: ' + format(percent_of_overlap, '.3f') + ' \\n')\n",
    "            #CHECKS TO MAKE SURE WE DID THIS RIGHT - correct end vs correct end\n",
    "            #if '+' not in strand:\n",
    "            #    print('ERROR: Top hit not in proper orientation.... SKIPPING -- PLEASE CHECK')\n",
    "            #    return\n",
    "            #parse contig #1 (left contig)\n",
    "            blat_length1, blat_start1, blat_end1 = int(line[14]),int(line[15]),int(line[16])\n",
    "            #print(blat_length1, blat_start1, blat_end1)\n",
    "            logFile.write('length = %i, start = %i, end = %i' % (blat_length1, blat_start1, blat_end1))\n",
    "            #parse contig #2 (right contig)\n",
    "            blat_length2, blat_start2, blat_end2 = int(line[10]),int(line[11]),int(line[12])\n",
    "            #print(blat_length2, blat_start2, blat_end2)\n",
    "            logFile.write('length = %i, start = %i, end = %i' % (blat_length2, blat_start2, blat_end2))\n",
    "            #Calculate offset  - to compensate for non-clean alignments (extension of left contig that does not overlap with adjacent contig)\n",
    "            offset = calculate_offset(overlap,blat_length1, blat_start1, blat_end1,Dir1,blat_length2, blat_start2, blat_end2,Dir2)\n",
    "            return offset\n",
    "###################################################################################################\n",
    "def calculate_offset(overlap,blat_length1, blat_start1, blat_end1,Dir1,blat_length2, blat_start2, blat_end2,Dir2):\n",
    "    global offset\n",
    "    if 'rc' in Dir1:\n",
    "        offset = blat_start1 - 0\n",
    "    else:\n",
    "        offset = blat_length1 - blat_end1\n",
    "    if offset < 3:\n",
    "        offset = 0\n",
    "    #print('\\nBLAT offset = ', offset)\n",
    "    logFile.write('\\nBLAT offset = ' + str(offset) + '\\n')\n",
    "    return offset\n",
    "\n",
    "###################################################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 elements in position dictionary from Zoey PacBio contigs....\n"
     ]
    }
   ],
   "source": [
    "#write_AGP_header(agpFile)\n",
    "posDict, offset_BLAT = {}, []\n",
    "\n",
    "for i in range(1,len(curated_contigDict)+1): \n",
    "    curr_index = i\n",
    "    offset = 0 #set equal to zero at beginning, will change if there is one from parsing the blat hit(s)\n",
    "    #If last entry, automatically goes in\n",
    "    if i == len(curated_contigDict):\n",
    "        chrom1,start1,end1,contigID1,Dir1,length1 = curated_contigDict[curr_index][0],int(curated_contigDict[curr_index][1]),int(curated_contigDict[curr_index][2]), curated_contigDict[curr_index][3], curated_contigDict[curr_index][4], int(curated_contigDict[curr_index][5])\n",
    "        posDict[i] = [chrom1,start1,end1,contigID1,Dir1,length1,int('0'),int('0'),'na']\n",
    "        continue\n",
    "        \n",
    "    #1. Reading in coordinates from contigList\n",
    "    chrom1,start1,end1,contigID1,Dir1,length1,chrom2,start2,end2,contigID2,Dir2,length2 = read_line(curated_contigDict, curr_index, i)\n",
    "    \n",
    "    #2. Checking contigs are on same chromosome\n",
    "    if chrom1 != chrom2:# or i == 1: #This is first contig on chromosome, need to process it first\n",
    "        #continue\n",
    "        process_first_contig_on_chrom(chrom1,start1,end1,contigID1,Dir1,length1) \n",
    "        continue\n",
    "    #print ('\\n#',contigID1, contigID2,'\\n',chrom1,start1,end1,contigID1,Dir1,length1,'\\n',chrom2,start2,end2,contigID2,Dir2,length2)\n",
    "    \n",
    "    #3. Determines the overlap/orientation of the two contigs\n",
    "    determine_contig_overlap(end1,contigID1,Dir1,length1,end2,contigID2,Dir2,length2)\n",
    "\n",
    "    #4. BLAT the properly oriented contig ends against one another\n",
    "    #     and parse the results\n",
    "    run_blat(wkDir)\n",
    "    parse_blat(wkDir,overlap,contigID1,Dir1,extract_coord1,contigID2,Dir2,extract_coord2)\n",
    "    if offset > 0:\n",
    "        offset_BLAT.append([contigID1,Dir1,extract_coord1,contigID2,Dir2,extract_coord2,overlap])\n",
    "    \n",
    "    #save contig1 information to dictionary\n",
    "    posDict[i] = [chrom1,start1,end1,contigID1,Dir1,length1,overlap,offset,contigID2]\n",
    "\n",
    "\n",
    "    #print('###################\\n')\n",
    "    #if i > 2:\n",
    "    #    break\n",
    "print('%i elements in position dictionary from Zoey PacBio contigs....' % (len(posDict)))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in posDict:\\n    print (posDict[i][0:9])'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in posDict:\n",
    "    print (posDict[i][0:9])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell reads through the spanned gaps per chromosome that Feichen generated and it saves each gap that has sequence that spans each contig-contig junction (makes sure that the gap contains sequence from both the left and right contig of which it is trying to connect). If a gap does not meet that requirement, it will not be incorporated into the Zoey AGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placed 17 filled contig-contig gap(s)\n"
     ]
    }
   ],
   "source": [
    "contigGapFile = open(wkDir + 'input/filled_gaps/' + CHROM + '/' + CHROM + '_gaps_fill.bed.sorted','r')\n",
    "contigGap_PosDict, contigGapCount = {}, 0\n",
    "\n",
    "for line in contigGapFile:\n",
    "    line=line.rstrip().split('\\t')\n",
    "    contigGapCount+=1\n",
    "    \n",
    "    filledGap_Chrom, filledGap_Start, filledGap_End, filledGap_Dir, filledGap_ID = line[0],int(line[1]),int(line[2]),line[3],line[4]\n",
    "    if '+' in filledGap_Dir:\n",
    "        filledGap_Dir = 'fwd'\n",
    "    else:\n",
    "        filledGap_Dir = 'rc'\n",
    "    filledGap_ID = filledGap_ID.replace('.fa','')\n",
    "    \n",
    "    for i in range(1,len(posDict)):\n",
    "        z_chrom, z_start, z_end, z_ID, z_gap, z_overlap = posDict[i][0],int(posDict[i][1]),int(posDict[i][2]),posDict[i][3],int(posDict[i][6]),int(posDict[i][7])\n",
    "        z_next_chrom, z_next_start, z_next_end, z_next_ID = posDict[i+1][0],int(posDict[i+1][1]),int(posDict[i+1][2]),posDict[i+1][3]\n",
    "        if z_chrom != filledGap_Chrom:\n",
    "            print('ERROR: not same chrom')\n",
    "            sys.exit()\n",
    "        if filledGap_Start < z_end and filledGap_End > z_end:\n",
    "            if filledGap_Start < z_next_start and filledGap_End > z_next_start:\n",
    "                filledGapLength = filledGap_End - filledGap_Start + 1\n",
    "                #calculate the new overlap value for the contig to the left of the filled gap\n",
    "                prev_overlap = z_end - filledGap_Start\n",
    "                \n",
    "                #Calculate the overlap with the filled gap contig and the zoey contig to the right of the filled gap\n",
    "                filledGapOverlap = filledGap_End - z_next_start\n",
    "                \n",
    "                #add the information for this filled gap to its dictionary\n",
    "                contigGap_PosDict[contigGapCount] = [filledGap_Chrom, filledGap_Start, filledGap_End, filledGap_ID, filledGap_Dir, filledGapLength, filledGapOverlap, int('0'), z_next_ID]\n",
    "                \n",
    "                #reset the previous contigs' overlap values and offset values equal to zero\n",
    "                posDict[i][6],posDict[i][7],posDict[i][8] = prev_overlap,int('0'),filledGap_ID\n",
    "\n",
    "contigGapFile.close() \n",
    "print('Placed %i filled contig-contig gap(s)' % contigGapCount)\n",
    "\n",
    "#sorted(posDict, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr18', 14843284, 14858955, 'chr18_11', 'fwd', 15672, 4669, 0, 'CTG-0274']\n",
      "['chr18', 17949751, 17976059, 'chr18_12', 'rc', 26309, 11026, 0, 'CTG-0878']\n",
      "['chr18', 18349537, 18394389, 'chr18_13', 'rc', 44853, 4516, 0, 'CTG-1134']\n",
      "['chr18', 18535710, 18596725, 'chr18_17', 'fwd', 61016, 8409, 0, 'CTG-0810']\n",
      "['chr18', 19075360, 19097577, 'chr18_18', 'fwd', 22218, 5653, 0, 'CTG-0953']\n",
      "['chr18', 19360226, 19374096, 'chr18_19', 'fwd', 13871, 6148, 0, 'CTG-0581']\n",
      "['chr18', 20984891, 21004225, 'chr18_21', 'rc', 19335, 3420, 0, 'CTG-0483']\n",
      "['chr18', 26335116, 26351755, 'chr18_26', 'fwd', 16640, 2754, 0, 'CTG-0458']\n",
      "['chr18', 28158514, 28167510, 'chr18_27', 'rc', 8997, 4834, 0, 'CTG-0416']\n",
      "['chr18', 30586423, 30615079, 'chr18_30', 'fwd', 28657, 5577, 0, 'CTG-0235']\n",
      "['chr18', 39302838, 39332123, 'chr18_35', 'fwd', 29286, 5822, 0, 'CTG-0756']\n",
      "['chr18', 40419903, 40447955, 'chr18_37', 'fwd', 28053, 17673, 0, 'CTG-2129']\n",
      "['chr18', 40428214, 40533342, 'chr18_38', 'rc', 105129, 3803, 0, 'CTG-0720']\n",
      "['chr18', 41992241, 42009357, 'chr18_41', 'rc', 17117, 5209, 0, 'CTG-0272']\n",
      "['chr18', 45351645, 45376318, 'chr18_43', 'fwd', 24674, 8526, 0, 'CTG-0213']\n",
      "['chr18', 49540932, 49559570, 'chr18_46', 'rc', 18639, 7464, 0, 'CTG-1000']\n",
      "['chr18', 49739802, 49749138, 'chr18_47', 'fwd', 9337, 2299, 0, 'CTG-0282']\n"
     ]
    }
   ],
   "source": [
    "for i in contigGap_PosDict:\n",
    "    print(contigGap_PosDict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell \"sorts\" the dictionary that keeps track of the placement of each contig. It merges the contig positional dictionary (posDict) with the filled gap dictionary (contigGap_PosDict) to create totalDict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total AGP will now include 67 elements (Zoey PacBio contigs (CTG-XXXX) and spanned gaps (chrX_N))\n"
     ]
    }
   ],
   "source": [
    "count, totalDict = 0, {}\n",
    "\n",
    "for j in range(1, len(posDict)+1):\n",
    "    count += 1\n",
    "    if j == len(posDict):\n",
    "        totalDict[count] = posDict[j]\n",
    "        continue\n",
    "    z_chrom, z_start, z_end = posDict[j][0],int(posDict[j][1]),int(posDict[j][2])\n",
    "    z_next_chrom, z_next_start, z_next_end, z_next_ID = posDict[j+1][0],int(posDict[j+1][1]),int(posDict[j+1][2]),posDict[j+1][3]\n",
    "    totalDict[count] = posDict[j]\n",
    "    for i in contigGap_PosDict:\n",
    "        filledGap_Chrom, filledGap_Start, filledGap_End, overlapping_ID = contigGap_PosDict[i][0],int(contigGap_PosDict[i][1]),int(contigGap_PosDict[i][2]),contigGap_PosDict[i][8]\n",
    "        #print(z_next_ID, overlapping_ID)\n",
    "        if z_chrom != filledGap_Chrom:\n",
    "            print('ERROR: not same chrom!!')\n",
    "            sys.exit()\n",
    "        if z_next_ID == overlapping_ID:\n",
    "            count += 1\n",
    "            totalDict[count] = contigGap_PosDict[i]\n",
    "        \"\"\"else:\n",
    "            print('doesnt work')\"\"\"\n",
    "\n",
    "print('The total AGP will now include %i elements (Zoey PacBio contigs (CTG-XXXX) and spanned gaps (chrX_N))' % len(totalDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['chr18', 2619, 26992, 'CTG-1462', 'rc', 24712, 4849, 0, 'CTG-0201']\n",
      "2 ['chr18', 22143, 3966426, 'CTG-0201', 'rc', 3968428, 1729, 0, 'CTG-1861']\n",
      "3 ['chr18', 3964697, 3978047, 'CTG-1861', 'fwd', 13154, 2637, 0, 'CTG-0743']\n",
      "4 ['chr18', 3975410, 4660269, 'CTG-0743', 'fwd', 681475, 25890, 0, 'CTG-0770']\n",
      "5 ['chr18', 4634379, 5281622, 'CTG-0770', 'rc', 639396, 21363, 0, 'CTG-0177']\n",
      "6 ['chr18', 5260259, 9645181, 'CTG-0177', 'rc', 4363384, 6495, 0, 'CTG-0767']\n",
      "7 ['chr18', 9638686, 10286737, 'CTG-0767', 'rc', 647068, 2059, 0, 'CTG-0615']\n",
      "8 ['chr18', 10284678, 11357644, 'CTG-0615', 'rc', 1078170, 37187, 0, 'CTG-1278']\n",
      "9 ['chr18', 11320457, 11367174, 'CTG-1278', 'fwd', 37673, 40908, 0, 'CTG-0400']\n",
      "10 ['chr18', 11326266, 13501863, 'CTG-0400', 'rc', 2190587, -4852, 0, 'CTG-0564']\n",
      "11 ['chr18', 13506715, 14852995, 'CTG-0564', 'rc', 1349347, 9711, 0, 'chr18_11']\n",
      "12 ['chr18', 14843284, 14858955, 'chr18_11', 'fwd', 15672, 4669, 0, 'CTG-0274']\n",
      "13 ['chr18', 14854286, 17956069, 'CTG-0274', 'rc', 3082702, 6318, 0, 'chr18_12']\n",
      "14 ['chr18', 17949751, 17976059, 'chr18_12', 'rc', 26309, 11026, 0, 'CTG-0878']\n",
      "15 ['chr18', 17965033, 18359454, 'CTG-0878', 'rc', 395029, 9917, 0, 'chr18_13']\n",
      "16 ['chr18', 18349537, 18394389, 'chr18_13', 'rc', 44853, 4516, 0, 'CTG-1134']\n",
      "17 ['chr18', 18389873, 18474563, 'CTG-1134', 'fwd', 85495, 4029, 0, 'CTG-1314']\n",
      "18 ['chr18', 18470534, 18504760, 'CTG-1314', 'fwd', 34113, 13268, 0, 'CTG-1776']\n",
      "19 ['chr18', 18491492, 18506121, 'CTG-1776', 'rc', 14596, 1360, 0, 'CTG-1294']\n",
      "20 ['chr18', 18504761, 18543987, 'CTG-1294', 'fwd', 38857, 8277, 0, 'chr18_17']\n",
      "21 ['chr18', 18535710, 18596725, 'chr18_17', 'fwd', 61016, 8409, 0, 'CTG-0810']\n",
      "22 ['chr18', 18588316, 19084754, 'CTG-0810', 'rc', 490363, 9394, 0, 'chr18_18']\n",
      "23 ['chr18', 19075360, 19097577, 'chr18_18', 'fwd', 22218, 5653, 0, 'CTG-0953']\n",
      "24 ['chr18', 19091924, 19366433, 'CTG-0953', 'rc', 273581, 6207, 0, 'chr18_19']\n",
      "25 ['chr18', 19360226, 19374096, 'chr18_19', 'fwd', 13871, 6148, 0, 'CTG-0581']\n",
      "26 ['chr18', 19367948, 20648758, 'CTG-0581', 'fwd', 1280510, 13620, 0, 'CTG-0901']\n",
      "27 ['chr18', 20635138, 20993149, 'CTG-0901', 'rc', 355818, 8258, 0, 'chr18_21']\n",
      "28 ['chr18', 20984891, 21004225, 'chr18_21', 'rc', 19335, 3420, 0, 'CTG-0483']\n",
      "29 ['chr18', 21000805, 22654130, 'CTG-0483', 'rc', 1655346, 24646, 0, 'CTG-0776']\n",
      "30 ['chr18', 22629484, 23228962, 'CTG-0776', 'rc', 597680, 14898, 0, 'CTG-0412']\n",
      "31 ['chr18', 23214064, 25317843, 'CTG-0412', 'rc', 2106211, -14267, 0, 'CTG-0630']\n",
      "32 ['chr18', 25332110, 26328164, 'CTG-0630', 'fwd', 1034698, 20307, 0, 'CTG-1329']\n",
      "33 ['chr18', 26307857, 26340773, 'CTG-1329', 'rc', 32757, 5657, 0, 'chr18_26']\n",
      "34 ['chr18', 26335116, 26351755, 'chr18_26', 'fwd', 16640, 2754, 0, 'CTG-0458']\n",
      "35 ['chr18', 26349001, 28160518, 'CTG-0458', 'fwd', 1814553, 2004, 0, 'chr18_27']\n",
      "36 ['chr18', 28158514, 28167510, 'chr18_27', 'rc', 8997, 4834, 0, 'CTG-0416']\n",
      "37 ['chr18', 28162676, 30223054, 'CTG-0416', 'rc', 2045472, 5188, 0, 'CTG-1241']\n",
      "38 ['chr18', 30217866, 30259696, 'CTG-1241', 'rc', 47540, 11141, 5040, 'CTG-0907']\n",
      "39 ['chr18', 30248555, 30591231, 'CTG-0907', 'rc', 349004, 4808, 0, 'chr18_30']\n",
      "40 ['chr18', 30586423, 30615079, 'chr18_30', 'fwd', 28657, 5577, 0, 'CTG-0235']\n",
      "41 ['chr18', 30609502, 34128003, 'CTG-0235', 'fwd', 3508078, 10472, 0, 'CTG-0351']\n",
      "42 ['chr18', 34117531, 36616051, 'CTG-0351', 'rc', 2534292, -13551, 0, 'CTG-0725']\n",
      "43 ['chr18', 36629602, 37366888, 'CTG-0725', 'fwd', 736753, -51643, 0, 'CTG-0432']\n",
      "44 ['chr18', 37418531, 39290284, 'CTG-0432', 'fwd', 1950806, 13916, 0, 'CTG-1297']\n",
      "45 ['chr18', 39276368, 39312643, 'CTG-1297', 'rc', 35966, 9805, 0, 'chr18_35']\n",
      "46 ['chr18', 39302838, 39332123, 'chr18_35', 'fwd', 29286, 5822, 0, 'CTG-0756']\n",
      "47 ['chr18', 39326301, 39981535, 'CTG-0756', 'fwd', 668698, 16254, 0, 'CTG-0835']\n",
      "48 ['chr18', 39965281, 40427697, 'CTG-0835', 'fwd', 450689, 7794, 0, 'chr18_37']\n",
      "49 ['chr18', 40419903, 40447955, 'chr18_37', 'fwd', 28053, 17673, 0, 'CTG-2129']\n",
      "50 ['chr18', 40430282, 40438128, 'CTG-2129', 'rc', 7821, 9914, 0, 'chr18_38']\n",
      "51 ['chr18', 40428214, 40533342, 'chr18_38', 'rc', 105129, 3803, 0, 'CTG-0720']\n",
      "52 ['chr18', 40529539, 41359396, 'CTG-0720', 'fwd', 738619, 17872, 0, 'CTG-1048']\n",
      "53 ['chr18', 41341524, 41503975, 'CTG-1048', 'fwd', 164381, 10209, 0, 'CTG-0817']\n",
      "54 ['chr18', 41493766, 41997929, 'CTG-0817', 'rc', 504439, 5688, 0, 'chr18_41']\n",
      "55 ['chr18', 41992241, 42009357, 'chr18_41', 'rc', 17117, 5209, 0, 'CTG-0272']\n",
      "56 ['chr18', 42004148, 45129980, 'CTG-0272', 'fwd', 3124127, -15243, 0, 'CTG-0989']\n",
      "57 ['chr18', 45145223, 45362298, 'CTG-0989', 'fwd', 216468, 10653, 0, 'chr18_43']\n",
      "58 ['chr18', 45351645, 45376318, 'chr18_43', 'fwd', 24674, 8526, 0, 'CTG-0213']\n",
      "59 ['chr18', 45367792, 49109540, 'CTG-0213', 'fwd', 3736794, 25995, 0, 'CTG-1240']\n",
      "60 ['chr18', 49083545, 49130813, 'CTG-1240', 'rc', 47251, 34303, 0, 'CTG-0854']\n",
      "61 ['chr18', 49096510, 49548067, 'CTG-0854', 'fwd', 454291, 7135, 0, 'chr18_46']\n",
      "62 ['chr18', 49540932, 49559570, 'chr18_46', 'rc', 18639, 7464, 0, 'CTG-1000']\n",
      "63 ['chr18', 49552106, 49746838, 'CTG-1000', 'fwd', 194595, 7036, 0, 'chr18_47']\n",
      "64 ['chr18', 49739802, 49749138, 'chr18_47', 'fwd', 9337, 2299, 0, 'CTG-0282']\n",
      "65 ['chr18', 49746839, 52779109, 'CTG-0282', 'fwd', 3034721, 10361, 0, 'CTG-0620']\n",
      "66 ['chr18', 52768748, 53825339, 'CTG-0620', 'rc', 1057651, -9050, 0, 'CTG-0459']\n",
      "67 ['chr18', 53834389, 55739311, 'CTG-0459', 'rc', 1823704, 0, 0, 'na']\n"
     ]
    }
   ],
   "source": [
    "for i in totalDict:\n",
    "    print(i, totalDict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_first_agp_contig(agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig):\n",
    "    agp_prev_chrom, agp_prev_overlap, prev_offset = agp_chrom, 0, 0\n",
    "    \n",
    "    if direction == 'fwd':\n",
    "        direction = '+' #changes notation of the direction\n",
    "    if direction == 'rc':\n",
    "        direction = '-'  #changes notation of the direction\n",
    "    \n",
    "    #Specially process those with offsets > 0\n",
    "    if offset > 0 or prev_offset > 0:\n",
    "        info = process_blat_offsets(agp_prev_chrom, agp_prev_overlap, prev_offset, agp_start, agp_end, overlap, offset,direction)\n",
    "    #Those with BLAT offsets = 0\n",
    "    else:\n",
    "        agp_start, agp_end = 1, length\n",
    "        contig_start, contig_end = 1, length\n",
    "        info = [agp_prev_chrom,agp_prev_overlap,agp_start, agp_end,contig_start,contig_end,direction,offset]\n",
    "    \n",
    "    return info\n",
    "########################################################################\n",
    "def process_blat_offsets(agp_prev_chrom, agp_prev_overlap, prev_offset, agp_start, agp_end, overlap, offset,direction):\n",
    "    if agp_prev_overlap < 5 and agp_prev_overlap > 0:\n",
    "        agp_prev_overlap = 0\n",
    "        \n",
    "    if prev_offset ==0  and offset > 0: #contig left of offset\n",
    "        agp_start = agp_end + 1\n",
    "        agp_end = agp_start + length + agp_prev_overlap\n",
    "\n",
    "        #Determine contig coordinates that align\n",
    "        if direction == 'fwd':\n",
    "            direction = '+' #changes notation of the direction\n",
    "            contig_start = 1 + agp_prev_overlap\n",
    "            contig_end = length\n",
    "        if direction == 'rc':\n",
    "            direction = '-'  #changes notation of the direction\n",
    "            contig_start = 1\n",
    "            contig_end = length - agp_prev_overlap\n",
    "\n",
    "    if prev_offset > 0 and offset == 0: #contig right of offset\n",
    "        agp_start = agp_end + 500 + 2 #compensate for added gap between the two which has length = 500\n",
    "        agp_end = agp_start + length + agp_prev_overlap\n",
    "\n",
    "        if direction == 'fwd':\n",
    "            direction = '+' #changes notation of the direction\n",
    "            contig_start = 1 + agp_prev_overlap\n",
    "            contig_end = length\n",
    "        if direction == 'rc':\n",
    "            direction = '-'  #changes notation of the direction\n",
    "            contig_start = 1\n",
    "            contig_end = length - agp_prev_overlap  \n",
    "            \n",
    "    if prev_offset > 0 and offset > 0:\n",
    "        print('This type of alignment needs to be readdressed...\\n')\n",
    "        sys.exit()\n",
    "        \n",
    "        \n",
    "    info = [agp_prev_chrom,agp_prev_overlap,agp_start, agp_end,contig_start,contig_end,direction,offset]\n",
    "    \n",
    "    return info\n",
    "\n",
    "########################################################################\n",
    "def process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end):\n",
    "    agp_prev_chrom, agp_prev_overlap, prev_offset = totalDict[i-1][0], int(totalDict[i-1][6]),int(totalDict[i-1][7])\n",
    "    \n",
    "    #Specially address those with BLAT offsets (unaligned sequence at the junctions)\n",
    "    if prev_offset > 0 or offset > 0:\n",
    "        info = process_blat_offsets(agp_prev_chrom, agp_prev_overlap, prev_offset, agp_start, agp_end, overlap, offset,direction)\n",
    "        return info\n",
    "    \n",
    "    #Junctions without unaligned sequence(s):\n",
    "    else:\n",
    "        if agp_prev_overlap < 5:\n",
    "            agp_prev_overlap = 0\n",
    "\n",
    "        #Determine contig coordinates that align\n",
    "        if direction == 'fwd':\n",
    "            direction = '+' #changes notation of the direction\n",
    "            contig_start = 1 + agp_prev_overlap\n",
    "            contig_end = length\n",
    "        if direction == 'rc':\n",
    "            direction = '-'  #changes notation of the direction\n",
    "            contig_start = 1\n",
    "            contig_end = length - agp_prev_overlap\n",
    "        \n",
    "        shift = contig_end - contig_start\n",
    "\n",
    "        #now calculate the AGP coordinates of where the contig goes\n",
    "        agp_start = agp_end + 1\n",
    "        agp_end = agp_start + shift + agp_prev_overlap\n",
    "        \n",
    "        info = [agp_prev_chrom,agp_prev_overlap,agp_start, agp_end,contig_start,contig_end,direction,offset]\n",
    "        return info       \n",
    "        \n",
    "########################################################################  \n",
    "def process_agp_GAP(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end):\n",
    "    gap_length = 10000\n",
    "    agp_start = agp_end + 1\n",
    "    agp_end = agp_start + gap_length\n",
    "    if 'CTG' in contigID:\n",
    "        gap_type = 'contig'\n",
    "    else:#To change once we add more types of contigs in here\n",
    "        gap_type = 'OTHER'\n",
    "    agp_prev_overlap = 0\n",
    "    \n",
    "    info = [agp_chrom,agp_start,agp_end,gap_type,gap_length,agp_prev_overlap]\n",
    "    return info  \n",
    "\n",
    "########################################################################  \n",
    "def write_AGP_header(agpFile): #alter for each assembly\n",
    "    agpFile.write('##agp-version 2.0\\n# ORGANISM: Canis lupus familiaris\\n# TAX_ID: 9615\\n')\n",
    "    agpFile.write('# ASSEMBLY NAME: Zoey_v2\\n# ASSEMBLY DATE: 19-April-2017\\n')\n",
    "    agpFile.write('# GENOME CENTER: University of Michigan - J.M. Kidd Lab\\n')\n",
    "    agpFile.write('# DESCRIPTION: AGP specifying the assembly of chromosome 18 from primary PacBio contigs from FALCON assembly\\n')      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now putting the information in the curated contig set (contigs constituting the golden path) into the coordinates of Zoey, and adding gap positions, if present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Defining AGP outfile\\nagpFile = open(wkDir + \\'results/AGP_Zoey_Assembly_v2_\\' + CHROM + \\'.txt\\', \\'w\\')\\n\\n#Now putting them in the coordinates of the Zoey genome!! :) \\ncount, agp = 0, [] \\n\\nfor i in totalDict:\\n    count += 1\\n    agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig = totalDict[i][0:9]\\n    #print(\\'\\n#\\',contigID)\\n    #print(totalDict[i])\\n    \\n    #print(count,agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig)    \\n    \\n    #Processing first contig in dataset -OR- on a new chromosome\\n    if count == 1 or agp_chrom != agp_prev_chrom: \\n        count = 1\\n        info = process_first_agp_contig(agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig)\\n        agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction, offset = info[0:10]\\n        agp.append([agp_prev_chrom, agp_start, agp_end, count, \\'D\\', contigID, contig_start, contig_end, direction ])\\n        #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\\n    \\n    #Process next contig (not first contig on chrom)\\n    else:\\n        if overlap >= 0: #if contigs overlap --> NO GAP!\\n            info = process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\\n            agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction,offset = info[0:10]\\n            if offset > 0:\\n                #Add contig to the left of the gap\\n                agp.append([agp_chrom, agp_start, agp_end, count, \\'D\\', contigID, contig_start, contig_end, direction])\\n                #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\\n                #Add introduced gap from unaligned sequences from contig-contig junction BLAT\\n                count += 1\\n                agp.append([agp_chrom, agp_end+1, agp_end+501, count, \\'U\\', \\'500\\',\\'BLAT_gap\\',\\'no\\',\\'na\\'])\\n                #print(agp_chrom, agp_end+1, agp_end+501, count, \\'U\\', \\'500\\',\\'BLAT_gap\\',\\'no\\',\\'na\\')\\n            else:\\n                agp.append([agp_chrom, agp_start, agp_end, count, \\'D\\', contigID, contig_start, contig_end, direction])         \\n                #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\\n        else: #if contigs do not overlap --> GAP!\\n            #process contig to the left of the gap\\n            info = process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\\n            agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction,offset = info[0:10]\\n            agp.append([agp_chrom, agp_start, agp_end, count, \\'D\\', contigID, contig_start, contig_end, direction])\\n            #print(agp_chrom, agp_start, agp_end, count, \\'D\\', contigID, contig_start, contig_end, direction)\\n            \\n            #processing gap\\n            count += 1\\n            gap_info = process_agp_GAP(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\\n            agp_chrom,agp_start,agp_end,gap_type,gap_length,agp_prev_overlap = gap_info[0:7]\\n            agp.append([agp_chrom,agp_start,agp_end,count,\\'U\\',gap_length,gap_type,\\'no\\',\\'na\\'])\\n            #print(agp_chrom,agp_start,agp_end,count,\\'U\\',gap_length,gap_type,\\'no\\',\\'na\\')\\n    #if count > 15:\\n    #    break\\n\\n#Write AGP header lines\\nwrite_AGP_header(agpFile)\\n\\n#Write out to agp File the information for contigs/gaps\\nfor i in range(0,len(agp)):\\n    agpFile.write(\"\\t\".join(map(str,agp[i])) + \\'\\n\\')\\nagpFile.close()\\nlogFile.close()\\n\\nprint(\\'DONE!!\\')'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Defining AGP outfile\n",
    "agpFile = open(wkDir + 'results/AGP_Zoey_Assembly_v2_' + CHROM + '.txt', 'w')\n",
    "\n",
    "#Now putting them in the coordinates of the Zoey genome!! :) \n",
    "count, agp = 0, [] \n",
    "\n",
    "for i in totalDict:\n",
    "    count += 1\n",
    "    agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig = totalDict[i][0:9]\n",
    "    #print('\\n#',contigID)\n",
    "    #print(totalDict[i])\n",
    "    \n",
    "    #print(count,agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig)    \n",
    "    \n",
    "    #Processing first contig in dataset -OR- on a new chromosome\n",
    "    if count == 1 or agp_chrom != agp_prev_chrom: \n",
    "        count = 1\n",
    "        info = process_first_agp_contig(agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig)\n",
    "        agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction, offset = info[0:10]\n",
    "        agp.append([agp_prev_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction ])\n",
    "        #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\n",
    "    \n",
    "    #Process next contig (not first contig on chrom)\n",
    "    else:\n",
    "        if overlap >= 0: #if contigs overlap --> NO GAP!\n",
    "            info = process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\n",
    "            agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction,offset = info[0:10]\n",
    "            if offset > 0:\n",
    "                #Add contig to the left of the gap\n",
    "                agp.append([agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction])\n",
    "                #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\n",
    "                #Add introduced gap from unaligned sequences from contig-contig junction BLAT\n",
    "                count += 1\n",
    "                agp.append([agp_chrom, agp_end+1, agp_end+501, count, 'U', '500','BLAT_gap','no','na'])\n",
    "                #print(agp_chrom, agp_end+1, agp_end+501, count, 'U', '500','BLAT_gap','no','na')\n",
    "            else:\n",
    "                agp.append([agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction])         \n",
    "                #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\n",
    "        else: #if contigs do not overlap --> GAP!\n",
    "            #process contig to the left of the gap\n",
    "            info = process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\n",
    "            agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction,offset = info[0:10]\n",
    "            agp.append([agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction])\n",
    "            #print(agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction)\n",
    "            \n",
    "            #processing gap\n",
    "            count += 1\n",
    "            gap_info = process_agp_GAP(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\n",
    "            agp_chrom,agp_start,agp_end,gap_type,gap_length,agp_prev_overlap = gap_info[0:7]\n",
    "            agp.append([agp_chrom,agp_start,agp_end,count,'U',gap_length,gap_type,'no','na'])\n",
    "            #print(agp_chrom,agp_start,agp_end,count,'U',gap_length,gap_type,'no','na')\n",
    "    #if count > 15:\n",
    "    #    break\n",
    "\n",
    "#Write AGP header lines\n",
    "write_AGP_header(agpFile)\n",
    "\n",
    "#Write out to agp File the information for contigs/gaps\n",
    "for i in range(0,len(agp)):\n",
    "    agpFile.write(\"\\t\".join(map(str,agp[i])) + '\\n')\n",
    "agpFile.close()\n",
    "logFile.close()\n",
    "\n",
    "print('DONE!!')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!!\n"
     ]
    }
   ],
   "source": [
    "#Defining AGP outfile\n",
    "agpFile = open(wkDir + 'results/AGP_Zoey_Assembly_v2_' + CHROM + '.txt', 'w')\n",
    "\n",
    "#Now putting them in the coordinates of the Zoey genome!! :) \n",
    "count, agp = 0, [] \n",
    "\n",
    "for i in totalDict:\n",
    "    count += 1\n",
    "    agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig = totalDict[i][0:9]\n",
    "    #print('\\n#',contigID)\n",
    "    #print(totalDict[i])\n",
    "    \n",
    "    #print(count,agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig)    \n",
    "    \n",
    "    #Processing first contig in dataset -OR- on a new chromosome\n",
    "    if count == 1 or agp_chrom != agp_prev_chrom: \n",
    "        count = 1\n",
    "        info = process_first_agp_contig(agp_chrom, start, end, contigID, direction, length, overlap, offset, pairedContig)\n",
    "        agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction, offset = info[0:10]\n",
    "        agp.append([agp_prev_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction ])\n",
    "        #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\n",
    "    \n",
    "    #Process next contig (not first contig on chrom)\n",
    "    else:\n",
    "        if overlap >= 0: #if contigs overlap --> NO GAP!\n",
    "            info = process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\n",
    "            agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction,offset = info[0:10]\n",
    "            if offset > 0:\n",
    "                #Add contig to the left of the gap\n",
    "                agp.append([agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction])\n",
    "                #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\n",
    "                #Add introduced gap from unaligned sequences from contig-contig junction BLAT\n",
    "                count += 1\n",
    "                agp.append([agp_chrom, agp_end+1, agp_end+501, count, 'U', '500','BLAT_gap','no','na'])\n",
    "                #print(agp_chrom, agp_end+1, agp_end+501, count, 'U', '500','BLAT_gap','no','na')\n",
    "            else:\n",
    "                agp.append([agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction])         \n",
    "                #print(agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction)\n",
    "        else: #if contigs do not overlap --> GAP!\n",
    "            #process contig to the left of the gap\n",
    "            info = process_next_agp_contig(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\n",
    "            agp_prev_chrom,agp_prev_overlap,agp_start, agp_end, contig_start,contig_end,direction,offset = info[0:10]\n",
    "            agp.append([agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction])\n",
    "            #print(agp_chrom, agp_start, agp_end, count, 'D', contigID, contig_start, contig_end, direction)\n",
    "            \n",
    "            #processing gap\n",
    "            count += 1\n",
    "            gap_info = process_agp_GAP(agp_chrom, direction, length, overlap, offset, pairedContig, agp_start, agp_end)\n",
    "            agp_chrom,agp_start,agp_end,gap_type,gap_length,agp_prev_overlap = gap_info[0:7]\n",
    "            agp.append([agp_chrom,agp_start,agp_end,count,'U',gap_length,gap_type,'no','na'])\n",
    "            #print(agp_chrom,agp_start,agp_end,count,'U',gap_length,gap_type,'no','na')\n",
    "    #if count > 15:\n",
    "    #    break\n",
    "\n",
    "#Write AGP header lines\n",
    "write_AGP_header(agpFile)\n",
    "\n",
    "#Write out to agp File the information for contigs/gaps\n",
    "for i in range(0,len(agp)):\n",
    "    agpFile.write(\"\\t\".join(map(str,agp[i])) + '\\n')\n",
    "agpFile.close()\n",
    "logFile.close()\n",
    "\n",
    "print('DONE!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "def extract_contig_fasta(fastaRoot,contigID,orient,extract_coord1,extract_coord2):\n",
    "    #Contig 1\n",
    "    fasta_path1 = fastaRoot + contigID + '/' + contigID + '.fa'\n",
    "    cmd = 'samtools faidx %s %s:%i-%i  > %stemp/contig1.fa' % (fasta_path1,contigID,extract_coord1,extract_coord2,wkDir)\n",
    "    #print(cmd)\n",
    "    subprocess.call(cmd,shell=True)\n",
    "###################################################################################################\n",
    "def extract_filledGap_fasta(fastaRoot,contigID,orient,extract_coord1,extract_coord2):\n",
    "    #Contig 1\n",
    "    fasta_path1 = gap_fastaRoot + '/' + CHROM + '/' + contigID + '.fa'\n",
    "    cmd = 'samtools faidx %s %s:%i-%i  > %stemp/contig1.fa' % (fasta_path1,contigID,extract_coord1,extract_coord2,wkDir)\n",
    "    #print(cmd)\n",
    "    subprocess.call(cmd,shell=True)\n",
    "\n",
    "###################################################################################################    \n",
    "def reverse_comp_contig_fasta(wkDir):\n",
    "    cmd = 'fastarevcomp %stemp/contig1.fa > %stemp/contig1.fa.rc' % (wkDir,wkDir)\n",
    "    #print(cmd)\n",
    "    subprocess.call(cmd,shell=True)\n",
    "    \n",
    "    cmd = 'mv %stemp/contig1.fa.rc %stemp/seq.fa'  % (wkDir,wkDir)\n",
    "    #print(cmd)\n",
    "    subprocess.call(cmd,shell=True) \n",
    "###################################################################################################    \n",
    "def read_in_fasta(wkDir):    \n",
    "    inFile = open(wkDir + 'temp/seq.fa', 'r')\n",
    "    for line in inFile:\n",
    "        line=line.rstrip()\n",
    "        if '>' in line:\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line)\n",
    "    inFile.close()\n",
    "    return seq\n",
    "\n",
    "###################################################################################################    \n",
    "def reformat_fasta_file(wkDir,CHROM):\n",
    "    agp_Fasta = open(wkDir + 'results/AGP_Zoey_Assembly_v2_' + CHROM + '.fa', 'r')\n",
    "    tmpFile = open(wkDir + 'results/tmp.fa', 'w')\n",
    "\n",
    "    for line in agp_Fasta:\n",
    "        if '>' in line:\n",
    "            tmpFile.write(line)#Writes chrom ID\n",
    "            continue\n",
    "        seq=line.rstrip()\n",
    "        \n",
    "        start = 0\n",
    "        fasta_length = float(len(seq))\n",
    "        fasta_line_length = 80\n",
    "        Max = int(fasta_length/fasta_line_length)\n",
    "\n",
    "        for i in range(0,Max+1):\n",
    "            Line = seq[start:start+fasta_line_length]\n",
    "            start = start + fasta_line_length\n",
    "            tmpFile.write(Line + '\\n')\n",
    "            \"\"\"if i > 10:\n",
    "                break\"\"\"    \n",
    "\n",
    "    agp_Fasta.close()\n",
    "    tmpFile.close()\n",
    "    \n",
    "    cmd = 'mv %sresults/tmp.fa %sresults/AGP_Zoey_Assembly_v2_%s.fa'  % (wkDir,wkDir,CHROM)\n",
    "    subprocess.call(cmd,shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing out the sequence for 74 contigs and gaps to Zoey fasta file\n"
     ]
    }
   ],
   "source": [
    "agpFile = open(wkDir + 'results/AGP_Zoey_Assembly_v2_' + CHROM + '.txt', 'r')\n",
    "fastaRoot = '/home/ampend/links/kidd-lab/jmkidd-projects/zoey/contig-assignment/kmer-matches/eval1/'\n",
    "agp_Fasta = open(wkDir + 'results/AGP_Zoey_Assembly_v2_' + CHROM + '.fa', 'w')\n",
    "\n",
    "gap_fastaRoot = wkDir + 'input/filled_gaps/' + CHROM + '/'\n",
    "\n",
    "contigID, count, prev_chrom = '', 0, ''\n",
    "\n",
    "for line in agpFile:\n",
    "    if '#' in line:\n",
    "        continue\n",
    "    count+= 1\n",
    "    \n",
    "    line = line.rstrip().split('\\t')\n",
    "    contigID = line[5]\n",
    "    \n",
    "    seq = []\n",
    "    \n",
    "    if 'CTG' in contigID or 'chr' in contigID:\n",
    "        chrom, contigID, extract_coord1, extract_coord2, orient = line[0],line[5],int(line[6]),int(line[7]), line[8]\n",
    "        if 'CTG' in contigID:\n",
    "            #Extract fasta\n",
    "            extract_contig_fasta(fastaRoot,contigID,orient,extract_coord1,extract_coord2)\n",
    "        if 'chr' in contigID:\n",
    "            extract_filledGap_fasta(gap_fastaRoot,contigID,orient,extract_coord1,extract_coord2)\n",
    "        #Reverse complement extracted FASTA if needed\n",
    "        if '-' == orient:\n",
    "            reverse_comp_contig_fasta(wkDir)\n",
    "        else:\n",
    "            cmd = 'mv %stemp/contig1.fa %stemp/seq.fa'  % (wkDir,wkDir)\n",
    "            #print(cmd)\n",
    "            subprocess.call(cmd,shell=True) \n",
    "        \n",
    "        seq = read_in_fasta(wkDir)\n",
    "    else: #These are gaps   \n",
    "        gap_length = int(line[5])\n",
    "        seq = 'N' * gap_length\n",
    "    \n",
    "    #Writes '>' chromosome to the fasta file\n",
    "    if count == 1 or prev_chrom != chrom:\n",
    "        if count > 1:\n",
    "            agp_Fasta.write('\\n')\n",
    "        agp_Fasta.write('>' + chrom + '\\n')\n",
    "    \n",
    "    for i in range(0,len(seq)):\n",
    "        Seq = seq[i].upper()#.upper()print(seq[i])\n",
    "        agp_Fasta.write(Seq)\n",
    "\n",
    "    prev_chrom = chrom #reset prev_chrom identity\n",
    "\n",
    "\n",
    "print('Finished writing out the sequence for %i contigs and gaps to Zoey fasta file' % count)\n",
    "agpFile.close()\n",
    "agp_Fasta.close()\n",
    "\n",
    "#Reformat the fasta file to only have certain # of nucleotides per line\n",
    "reformat_fasta_file(wkDir,CHROM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have generated the golden path file. Below, I'm calculating statistics on the AGP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Counts\n",
      "67 contigs are in the Golden Path for Zoey\n",
      "7 gaps remain in the Golden Path for Zoey\n",
      "Of these 7 gaps, 1 gap(s) correspond(s) to BLAT gaps (unaligned sequences where gaps were introduced)\n",
      "\n",
      "##Statistics\n",
      "Average continuity on chr18 (in bp) = 7858764.86\n"
     ]
    }
   ],
   "source": [
    "agpFile = open(wkDir + 'results/AGP_Zoey_Assembly_v2_' + CHROM + '.txt', 'r')\n",
    "\n",
    "contig_count,gap_count,line_count,blat_gap_count = 0,0,0,0\n",
    "prev_Type,start_stop_list,contig_start = '',[],1\n",
    "\n",
    "for line in agpFile:\n",
    "    if '#' in line: #skips header\n",
    "        continue    \n",
    "    line = line.rstrip().split('\\t')\n",
    "    line_count += 1\n",
    "    chrom,start,end,num,Type = line[0], int(line[1]),int(line[2]),int(line[3]),line[4]\n",
    "    if 'D' in Type:\n",
    "        #this is a contig\n",
    "        contig_count += 1\n",
    "        if 'U' in prev_Type:\n",
    "            contig_start = start\n",
    "    if 'U' in Type:\n",
    "        #this is a gap\n",
    "        gap_count += 1\n",
    "        if 'BLAT' in line[6]:\n",
    "            blat_gap_count+=1\n",
    "        #print(start,end)\n",
    "        if 'D' in prev_Type:\n",
    "            contig_end = start - 1\n",
    "            start_stop_list.append([contig_start,contig_end])\n",
    "    prev_Type = Type\n",
    "    \n",
    "print('##Counts\\n%i contigs are in the Golden Path for Zoey' % contig_count)\n",
    "print('%i gaps remain in the Golden Path for Zoey' % gap_count)\n",
    "print('Of these %i gaps, %i gap(s) correspond(s) to BLAT gaps (unaligned sequences where gaps were introduced)' %(gap_count,blat_gap_count))\n",
    "\n",
    "continuous_contig_array = []\n",
    "for i in range(0,len(start_stop_list)):\n",
    "    start,end = int(start_stop_list[i][0]),int(start_stop_list[i][1])\n",
    "    length = end-start\n",
    "    continuous_contig_array.append(length)\n",
    "\n",
    "Average_continuity = format(np.mean(continuous_contig_array), '.2f') \n",
    "print('\\n##Statistics\\nAverage continuity on %s (in bp) = %s'% (CHROM, Average_continuity))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate continuity in CanFam3.1, we'll need to know the chromosome IDs and the chromosome lengths. \n",
    "\n",
    "The next cell stores the chromosome identifiers with the lengths of each chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chr16': 59632846, 'chr37': 30902991, 'chr35': 26524999, 'chr4': 88276631, 'chr26': 38964690, 'chr25': 51628933, 'chr13': 63241923, 'chr32': 38810281, 'chr27': 45876710, 'chr30': 40214260, 'chr31': 39895921, 'chr12': 72498081, 'chr20': 58134056, 'chr1': 122678785, 'chr10': 69331447, 'chr23': 52294480, 'chr14': 60966679, 'chr2': 85426708, 'chr38': 23914537, 'chr28': 41182112, 'chr5': 88915250, 'chr33': 31377067, 'chr19': 53741614, 'chr7': 80974532, 'chr8': 74330416, 'chr17': 64289059, 'chr22': 61439934, 'chr24': 47698779, 'chr9': 61074082, 'chr21': 50858623, 'chr6': 77573801, 'chr3': 91889043, 'chr11': 74389097, 'chr29': 41845238, 'chrM': 16727, 'chr15': 64190966, 'chr34': 42124431, 'chr18': 55844845, 'chr36': 30810995, 'chrX': 123869142}\n"
     ]
    }
   ],
   "source": [
    "chrom_length_file = open(wkDir + 'input/cyto_band.bed','r')\n",
    "chrom_lengths = {}\n",
    "\n",
    "for line in chrom_length_file:\n",
    "    line=line.rstrip().split('\\t')\n",
    "    chrom,length = line[0],int(line[2])\n",
    "    if 'chrUn' in chrom:\n",
    "        continue\n",
    "    chrom_lengths[chrom] = length\n",
    "    \n",
    "print (chrom_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will store the gaps separately on each chromosome so that we can calculate continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19553 gaps in the canFam3 assembly (not including chrUn)\n",
      "Average continuity for the genome in bp:  118532.19\n"
     ]
    }
   ],
   "source": [
    "gapFile = open(wkDir + 'input/gaps.bed.sorted','r')\n",
    "#to keep track of the previous call\n",
    "prev_chrom, prev_start, prev_end = '', '', ''\n",
    "#save continuous stretches to array\n",
    "cont_pos_list, per_chrom, count =  [], {}, 0 \n",
    "\n",
    "\n",
    "for line in gapFile:\n",
    "    line=line.rstrip().split('\\t')\n",
    "    chrom,start,end=line[0],int(line[1]),int(line[2])\n",
    "    if 'chrUn' in chrom:\n",
    "        continue\n",
    "    #FOR TESTING\n",
    "    \"\"\"if 'chr18' not in chrom:\n",
    "        continue\"\"\"\n",
    "    count+=1\n",
    "\n",
    "    #If first line in file\n",
    "    if count == 1:\n",
    "        per_chrom[chrom] = []\n",
    "        if start == 0: #gap is at the beginning of the chromosome\n",
    "            #Save for next\n",
    "            cont_start = end\n",
    "            prev_chrom, prev_start, prev_end = chrom, start, end\n",
    "            continue\n",
    "        #first continuous stretch on chromosome\n",
    "        cont_start = 0\n",
    "        cont_end = start - 1\n",
    "        cont_pos_list.append([count-1,cont_start,cont_end])\n",
    "        per_chrom[chrom].append([count-1,cont_start,cont_end])\n",
    "        \n",
    "        #next continuous stretch, define start\n",
    "        cont_start = end\n",
    "        #Save for next\n",
    "        prev_chrom, prev_start, prev_end = chrom, start, end\n",
    "        continue\n",
    "    #If the next call is on a different chromosome, must save the previous gap's info\n",
    "    if chrom not in prev_chrom:\n",
    "        per_chrom[chrom] = []\n",
    "        #previous continuous stretch\n",
    "        cont_end = chrom_lengths[prev_chrom]\n",
    "        cont_pos_list.append([count-1,cont_start,cont_end])\n",
    "        per_chrom[chrom].append([count-1,cont_start,cont_end])\n",
    "        #first continuous stretch on new chromosome\n",
    "        cont_start = 0\n",
    "        cont_end = start - 1\n",
    "        #next adjacent stretch, define start\n",
    "        cont_start = end      \n",
    "    else:\n",
    "        cont_end = start - 1\n",
    "        cont_pos_list.append([count-1,cont_start,cont_end])\n",
    "        per_chrom[chrom].append([count-1,cont_start,cont_end])\n",
    "        #next adjacent strech, define start\n",
    "        cont_start = end\n",
    "        \n",
    "    prev_chrom, prev_start, prev_end = chrom, start, end\n",
    "    \n",
    "\n",
    "print('There are %i gaps in the canFam3 assembly (not including chrUn)' % count)\n",
    "gapFile.close()\n",
    "\n",
    "\n",
    "#Calculating the continuity statistics\n",
    "continuous_contig_array = []\n",
    "for i in range(0,len(cont_pos_list)):\n",
    "    start,end = int(cont_pos_list[i][1]),int(cont_pos_list[i][2])\n",
    "    length = end-start\n",
    "    continuous_contig_array.append(length)    \n",
    "Average_continuity = format(np.mean(continuous_contig_array), '.2f')\n",
    "print('Average continuity for the genome in bp: ', Average_continuity)  \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will calculate the number of gaps per chromosome in the CanFam3.1 assembly as well as the average continuity value per chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome\tGap_Count\tAverageContinuity\n",
      "chr16 442 133897.94\n",
      "chr35 211 126727.09\n",
      "chr11 533 139018.32\n",
      "chr26 391 99154.57\n",
      "chr13 488 129005.97\n",
      "chr32 190 202505.99\n",
      "chr27 393 116399.34\n",
      "chr30 372 107145.10\n",
      "chrX 1032 119702.28\n",
      "chr12 482 150218.18\n",
      "chr20 687 83932.28\n",
      "chr23 308 169341.04\n",
      "chr10 744 92985.91\n",
      "chr25 384 133718.28\n",
      "chr14 345 175115.68\n",
      "chr2 828 102654.87\n",
      "chr38 308 79114.00\n",
      "chr15 637 100647.08\n",
      "chr5 892 98934.37\n",
      "chr9 764 79047.59\n",
      "chr33 264 118442.50\n",
      "chr19 304 177014.63\n",
      "chr7 607 132802.75\n",
      "chr8 583 126900.71\n",
      "chr17 513 124429.61\n",
      "chr22 371 165163.49\n",
      "chr4 622 141570.59\n",
      "chr24 455 104445.93\n",
      "chr31 288 138703.69\n",
      "chr21 374 135844.89\n",
      "chr6 786 98439.18\n",
      "chr3 707 129768.72\n",
      "chr29 264 157243.09\n",
      "chr1 1121 108669.12\n",
      "chr34 297 140893.48\n",
      "chr18 589 94481.08\n",
      "chr28 395 103803.70\n",
      "chr36 254 120487.31\n",
      "chr37 327 92451.86\n"
     ]
    }
   ],
   "source": [
    "#Continuity values per chromosome\n",
    "print('Chromosome\\tGap_Count\\tAverageContinuity')\n",
    "for i in per_chrom:\n",
    "    chrom = i\n",
    "    continuous_contig_array = []\n",
    "    for j in per_chrom[chrom]:\n",
    "        start = int(j[1])\n",
    "        end = int(j[2])\n",
    "        length = end - start\n",
    "        continuous_contig_array.append(length)\n",
    "    Average_continuity = format(np.mean(continuous_contig_array), '.2f')\n",
    "    print(chrom, len(per_chrom[chrom]),Average_continuity )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
